"
A PyProcessorTest is a test class for testing the behavior of PyProcessor
"
Class {
	#name : #PyProcessorTest,
	#superclass : #TestCase,
	#instVars : [
		'p'
	],
	#category : #'Roassal2-Plugins-PythonAnalyzer-Tests'
}

{ #category : #sources }
PyProcessorTest >> angleUtility [
^ 
'# -*- coding: utf-8 -*-
# Licensed under a 3-clause BSD style license - see LICENSE.rst

# Note that  files generated by lex/yacc not always fully py 2/3 compatible.
# Hence, the ``clean_parse_tables.py`` tool in the astropy-tools
# (https://github.com/astropy/astropy-tools) repository should be used to fix
# this when/if lextab/parsetab files are re-generated.

"""
This module contains utility functions that are for internal use in
astropy.coordinates.angles. Mainly they are conversions from one format
of data to another.
"""
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import os
from warnings import warn

import numpy as np

from .errors import (IllegalHourWarning, IllegalHourError,
                     IllegalMinuteWarning, IllegalMinuteError,
                     IllegalSecondWarning, IllegalSecondError)
from ..utils import format_exception
from .. import units as u


class _AngleParser(object):
    """
    Parses the various angle formats including:

       * 01:02:30.43 degrees
       * 1 2 0 hours
       * 1°2′3″
       * 1d2m3s
       * -1h2m3s

    This class should not be used directly.  Use `parse_angle`
    instead.
    """
    def __init__(self):
        # TODO: in principle, the parser should be invalidated if we change unit
        # system (from CDS to FITS, say).  Might want to keep a link to the
        # unit_registry used, and regenerate the parser/lexer if it changes.
        # Alternatively, perhaps one should not worry at all and just pre-
        # generate the parser for each release (as done for unit formats).
        # For some discussion of this problem, see
        # https://github.com/astropy/astropy/issues/5350#issuecomment-248770151
        if ''_parser'' not in _AngleParser.__dict__:
            _AngleParser._parser, _AngleParser._lexer = self._make_parser()

    @classmethod
    def _get_simple_unit_names(cls):
        simple_units = set(
            u.radian.find_equivalent_units(include_prefix_units=True))
        simple_unit_names = set()
        # We filter out degree and hourangle, since those are treated
        # separately.
        for unit in simple_units:
            if unit != u.deg and unit != u.hourangle:
                simple_unit_names.update(unit.names)
        return list(simple_unit_names)

    @classmethod
    def _make_parser(cls):
        from ..extern.ply import lex, yacc

        # List of token names.
        tokens = (
            ''SIGN'',
            ''UINT'',
            ''UFLOAT'',
            ''COLON'',
            ''DEGREE'',
            ''HOUR'',
            ''MINUTE'',
            ''SECOND'',
            ''SIMPLE_UNIT''
        )

        # NOTE THE ORDERING OF THESE RULES IS IMPORTANT!!
        # Regular expression rules for simple tokens
        def t_UFLOAT(t):
            r''((\d+\.\d*)|(\.\d+))([eE][+-−]?\d+)?''
            # The above includes Unicode "MINUS SIGN" \u2212.  It is
            # important to include the hyphen last, or the regex will
            # treat this as a range.
            t.value = float(t.value.replace(''−'', ''-''))
            return t

        def t_UINT(t):
            r''\d+''
            t.value = int(t.value)
            return t

        def t_SIGN(t):
            r''[+−-]''
            # The above include Unicode "MINUS SIGN" \u2212.  It is
            # important to include the hyphen last, or the regex will
            # treat this as a range.
            if t.value == ''+'':
                t.value = 1.0
            else:
                t.value = -1.0
            return t

        def t_SIMPLE_UNIT(t):
            t.value = u.Unit(t.value)
            return t
        t_SIMPLE_UNIT.__doc__ = ''|''.join(
            ''(?:{0})''.format(x) for x in cls._get_simple_unit_names())

        t_COLON = '':''
        t_DEGREE = r''d(eg(ree(s)?)?)?|°''
        t_HOUR = r''hour(s)?|h(r)?|ʰ''
        t_MINUTE = r''m(in(ute(s)?)?)?|′|\''|ᵐ''
        t_SECOND = r''s(ec(ond(s)?)?)?|″|\"|ˢ''

        # A string containing ignored characters (spaces)
        t_ignore = '' ''

        # Error handling rule
        def t_error(t):
            raise ValueError(
                "Invalid character at col {0}".format(t.lexpos))

        # Build the lexer
        # PY2: need str() to ensure we do not pass on a unicode object.
        lexer = lex.lex(optimize=True, lextab=str(''angle_lextab''),
                        outputdir=os.path.dirname(__file__))

        def p_angle(p):
            ''''''
            angle : hms
                  | dms
                  | arcsecond
                  | arcminute
                  | simple
            ''''''
            p[0] = p[1]

        def p_sign(p):
            ''''''
            sign : SIGN
                 |
            ''''''
            if len(p) == 2:
                p[0] = p[1]
            else:
                p[0] = 1.0

        def p_ufloat(p):
            ''''''
            ufloat : UFLOAT
                   | UINT
            ''''''
            p[0] = float(p[1])

        def p_colon(p):
            ''''''
            colon : sign UINT COLON ufloat
                  | sign UINT COLON UINT COLON ufloat
            ''''''
            if len(p) == 5:
                p[0] = (p[1] * p[2], p[4])
            elif len(p) == 7:
                p[0] = (p[1] * p[2], p[4], p[6])

        def p_spaced(p):
            ''''''
            spaced : sign UINT ufloat
                   | sign UINT UINT ufloat
            ''''''
            if len(p) == 4:
                p[0] = (p[1] * p[2], p[3])
            elif len(p) == 5:
                p[0] = (p[1] * p[2], p[3], p[4])

        def p_generic(p):
            ''''''
            generic : colon
                    | spaced
                    | sign UFLOAT
                    | sign UINT
            ''''''
            if len(p) == 2:
                p[0] = p[1]
            else:
                p[0] = p[1] * p[2]

        def p_hms(p):
            ''''''
            hms : sign UINT HOUR
                | sign UINT HOUR ufloat
                | sign UINT HOUR UINT MINUTE
                | sign UINT HOUR UFLOAT MINUTE
                | sign UINT HOUR UINT MINUTE ufloat
                | sign UINT HOUR UINT MINUTE ufloat SECOND
                | generic HOUR
            ''''''
            if len(p) == 3:
                p[0] = (p[1], u.hourangle)
            elif len(p) == 4:
                p[0] = (p[1] * p[2], u.hourangle)
            elif len(p) in (5, 6):
                p[0] = ((p[1] * p[2], p[4]), u.hourangle)
            elif len(p) in (7, 8):
                p[0] = ((p[1] * p[2], p[4], p[6]), u.hourangle)

        def p_dms(p):
            ''''''
            dms : sign UINT DEGREE
                | sign UINT DEGREE ufloat
                | sign UINT DEGREE UINT MINUTE
                | sign UINT DEGREE UFLOAT MINUTE
                | sign UINT DEGREE UINT MINUTE ufloat
                | sign UINT DEGREE UINT MINUTE ufloat SECOND
                | generic DEGREE
            ''''''
            if len(p) == 3:
                p[0] = (p[1], u.degree)
            elif len(p) == 4:
                p[0] = (p[1] * p[2], u.degree)
            elif len(p) in (5, 6):
                p[0] = ((p[1] * p[2], p[4]), u.degree)
            elif len(p) in (7, 8):
                p[0] = ((p[1] * p[2], p[4], p[6]), u.degree)

        def p_simple(p):
            ''''''
            simple : generic
                   | generic SIMPLE_UNIT
            ''''''
            if len(p) == 2:
                p[0] = (p[1], None)
            else:
                p[0] = (p[1], p[2])

        def p_arcsecond(p):
            ''''''
            arcsecond : generic SECOND
            ''''''
            p[0] = (p[1], u.arcsecond)

        def p_arcminute(p):
            ''''''
            arcminute : generic MINUTE
            ''''''
            p[0] = (p[1], u.arcminute)

        def p_error(p):
            raise ValueError

        # PY2: need str() to ensure we do not pass on a unicode object.
        parser = yacc.yacc(debug=False, tabmodule=str(''angle_parsetab''),
                           outputdir=os.path.dirname(__file__),
                           write_tables=True)

        return parser, lexer

    def parse(self, angle, unit, debug=False):
        try:
            found_angle, found_unit = self._parser.parse(
                angle, lexer=self._lexer, debug=debug)
        except ValueError as e:
            if str(e):
                raise ValueError("{0} in angle {1!r}".format(
                    str(e), angle))
            else:
                raise ValueError(
                    "Syntax error parsing angle {0!r}".format(angle))

        if unit is None and found_unit is None:
            raise u.UnitsError("No unit specified")

        return found_angle, found_unit


def _check_hour_range(hrs):
    """
    Checks that the given value is in the range (-24, 24).
    """
    if np.any(np.abs(hrs) == 24.):
        warn(IllegalHourWarning(hrs, ''Treating as 24 hr''))
    elif np.any(hrs < -24.) or np.any(hrs > 24.):
        raise IllegalHourError(hrs)


def _check_minute_range(m):
    """
    Checks that the given value is in the range [0,60].  If the value
    is equal to 60, then a warning is raised.
    """
    if np.any(m == 60.):
        warn(IllegalMinuteWarning(m, ''Treating as 0 min, +1 hr/deg''))
    elif np.any(m < -60.) or np.any(m > 60.):
        # "Error: minutes not in range [-60,60) ({0}).".format(min))
        raise IllegalMinuteError(m)


def _check_second_range(sec):
    """
    Checks that the given value is in the range [0,60].  If the value
    is equal to 60, then a warning is raised.
    """
    if np.any(sec == 60.):
        warn(IllegalSecondWarning(sec, ''Treating as 0 sec, +1 min''))
    elif sec is None:
        pass
    elif np.any(sec < -60.) or np.any(sec > 60.):
        # "Error: seconds not in range [-60,60) ({0}).".format(sec))
        raise IllegalSecondError(sec)


def check_hms_ranges(h, m, s):
    """
    Checks that the given hour, minute and second are all within
    reasonable range.
    """
    _check_hour_range(h)
    _check_minute_range(m)
    _check_second_range(s)
    return None


def parse_angle(angle, unit=None, debug=False):
    """
    Parses an input string value into an angle value.

    Parameters
    ----------
    angle : str
        A string representing the angle.  May be in one of the following forms:

            * 01:02:30.43 degrees
            * 1 2 0 hours
            * 1°2′3″
            * 1d2m3s
            * -1h2m3s

    unit : `~astropy.units.UnitBase` instance, optional
        The unit used to interpret the string.  If ``unit`` is not
        provided, the unit must be explicitly represented in the
        string, either at the end or as number separators.

    debug : bool, optional
        If `True`, print debugging information from the parser.

    Returns
    -------
    value, unit : tuple
        ``value`` is the value as a floating point number or three-part
        tuple, and ``unit`` is a `Unit` instance which is either the
        unit passed in or the one explicitly mentioned in the input
        string.
    """
    return _AngleParser().parse(angle, unit, debug=debug)


def degrees_to_dms(d):
    """
    Convert a floating-point degree value into a ``(degree, arcminute,
    arcsecond)`` tuple.
    """
    sign = np.copysign(1.0, d)

    (df, d) = np.modf(np.abs(d))  # (degree fraction, degree)
    (mf, m) = np.modf(df * 60.)  # (minute fraction, minute)
    s = mf * 60.

    return np.floor(sign * d), sign * np.floor(m), sign * s


def dms_to_degrees(d, m, s=None):
    """
    Convert degrees, arcminute, arcsecond to a float degrees value.
    """

    _check_minute_range(m)
    _check_second_range(s)

    # determine sign
    sign = np.copysign(1.0, d)

    try:
        d = np.floor(np.abs(d))
        if s is None:
            m = np.abs(m)
            s = 0
        else:
            m = np.floor(np.abs(m))
            s = np.abs(s)
    except ValueError:
        raise ValueError(format_exception(
            "{func}: dms values ({1[0]},{2[1]},{3[2]}) could not be "
            "converted to numbers.", d, m, s))

    return sign * (d + m / 60. + s / 3600.)


def hms_to_hours(h, m, s=None):
    """
    Convert hour, minute, second to a float hour value.
    """

    check_hms_ranges(h, m, s)

    # determine sign
    sign = np.copysign(1.0, h)

    try:
        h = np.floor(np.abs(h))
        if s is None:
            m = np.abs(m)
            s = 0
        else:
            m = np.floor(np.abs(m))
            s = np.abs(s)
    except ValueError:
        raise ValueError(format_exception(
            "{func}: HMS values ({1[0]},{2[1]},{3[2]}) could not be "
            "converted to numbers.", h, m, s))

    return sign * (h + m / 60. + s / 3600.)


def hms_to_degrees(h, m, s):
    """
    Convert hour, minute, second to a float degrees value.
    """

    return hms_to_hours(h, m, s) * 15.


def hms_to_radians(h, m, s):
    """
    Convert hour, minute, second to a float radians value.
    """

    return u.degree.to(u.radian, hms_to_degrees(h, m, s))


def hms_to_dms(h, m, s):
    """
    Convert degrees, arcminutes, arcseconds to an ``(hour, minute, second)``
    tuple.
    """

    return degrees_to_dms(hms_to_degrees(h, m, s))


def hours_to_decimal(h):
    """
    Convert any parseable hour value into a float value.
    """
    from . import angles
    return angles.Angle(h, unit=u.hourangle).hour


def hours_to_radians(h):
    """
    Convert an angle in Hours to Radians.
    """

    return u.hourangle.to(u.radian, h)


def hours_to_hms(h):
    """
    Convert an floating-point hour value into an ``(hour, minute,
    second)`` tuple.
    """

    sign = np.copysign(1.0, h)

    (hf, h) = np.modf(np.abs(h))  # (degree fraction, degree)
    (mf, m) = np.modf(hf * 60.0)  # (minute fraction, minute)
    s = mf * 60.0

    return (np.floor(sign * h), sign * np.floor(m), sign * s)


def radians_to_degrees(r):
    """
    Convert an angle in Radians to Degrees.
    """
    return u.radian.to(u.degree, r)


def radians_to_hours(r):
    """
    Convert an angle in Radians to Hours.
    """
    return u.radian.to(u.hourangle, r)


def radians_to_hms(r):
    """
    Convert an angle in Radians to an ``(hour, minute, second)`` tuple.
    """

    hours = radians_to_hours(r)
    return hours_to_hms(hours)


def radians_to_dms(r):
    """
    Convert an angle in Radians to an ``(degree, arcminute,
    arcsecond)`` tuple.
    """

    degrees = u.radian.to(u.degree, r)
    return degrees_to_dms(degrees)


def sexagesimal_to_string(values, precision=None, pad=False, sep=('':'',),
                          fields=3):
    """
    Given an already separated tuple of sexagesimal values, returns
    a string.

    See `hours_to_string` and `degrees_to_string` for a higher-level
    interface to this functionality.
    """

    # If the coordinates are negative, we need to take the absolute value of
    # the (arc)minutes and (arc)seconds. We need to use np.abs because abs(-0)
    # is -0.
    values = (values[0], np.abs(values[1]), np.abs(values[2]))

    if pad:
        # Check to see if values[0] is negative, using np.copysign to handle -0
        if np.copysign(1.0, values[0]) == -1:
            pad = 3
        else:
            pad = 2
    else:
        pad = 0

    if not isinstance(sep, tuple):
        sep = tuple(sep)

    if fields < 1 or fields > 3:
        raise ValueError(
            "fields must be 1, 2, or 3")

    if not sep:  # empty string, False, or None, etc.
        sep = ('''', '''', '''')
    elif len(sep) == 1:
        if fields == 3:
            sep = sep + (sep[0], '''')
        elif fields == 2:
            sep = sep + ('''', '''')
        else:
            sep = ('''', '''', '''')
    elif len(sep) == 2:
        sep = sep + ('''',)
    elif len(sep) != 3:
        raise ValueError(
            "Invalid separator specification for converting angle to string.")

    # Simplify the expression based on the requested precision.  For
    # example, if the seconds will round up to 60, we should convert
    # it to 0 and carry upwards.  If the field is hidden (by the
    # fields kwarg) we round up around the middle, 30.0.
    if precision is None:
        rounding_thresh = 60.0 - (10.0 ** -4)
    else:
        rounding_thresh = 60.0 - (10.0 ** -precision)

    values = list(values)
    if fields == 3 and values[2] >= rounding_thresh:
        values[2] = 0.0
        values[1] += 1.0
    elif fields < 3 and values[2] >= 30.0:
        values[1] += 1.0

    if fields >= 2 and int(values[1]) >= 60.0:
        values[1] = 0.0
        values[0] += 1.0
    elif fields < 2 and int(values[1]) >= 30.0:
        values[0] += 1.0

    literal = []
    last_value = ''''
    literal.append(''{0:0{pad}.0f}{sep[0]}'')
    if fields >= 2:
        literal.append(''{1:02d}{sep[1]}'')
    if fields == 3:
        if precision is None:
            last_value = ''{0:.4f}''.format(abs(values[2]))
            last_value = last_value.rstrip(''0'').rstrip(''.'')
        else:
            last_value = ''{0:.{precision}f}''.format(
                abs(values[2]), precision=precision)
        if len(last_value) == 1 or last_value[1] == ''.'':
            last_value = ''0'' + last_value
        literal.append(''{last_value}{sep[2]}'')
    literal = ''''.join(literal)
    return literal.format(values[0], int(abs(values[1])), abs(values[2]),
                          sep=sep, pad=pad,
                          last_value=last_value)


def hours_to_string(h, precision=5, pad=False, sep=(''h'', ''m'', ''s''),
                    fields=3):
    """
    Takes a decimal hour value and returns a string formatted as hms with
    separator specified by the ''sep'' parameter.

    ``h`` must be a scalar.
    """
    h, m, s = hours_to_hms(h)
    return sexagesimal_to_string((h, m, s), precision=precision, pad=pad,
                                 sep=sep, fields=fields)


def degrees_to_string(d, precision=5, pad=False, sep='':'', fields=3):
    """
    Takes a decimal hour value and returns a string formatted as dms with
    separator specified by the ''sep'' parameter.

    ``d`` must be a scalar.
    """
    d, m, s = degrees_to_dms(d)
    return sexagesimal_to_string((d, m, s), precision=precision, pad=pad,
                                 sep=sep, fields=fields)


def angular_separation(lon1, lat1, lon2, lat2):
    """
    Angular separation between two points on a sphere.

    Parameters
    ----------
    lon1, lat1, lon2, lat2 : `Angle`, `~astropy.units.Quantity` or float
        Longitude and latitude of the two points. Quantities should be in
        angular units; floats in radians.

    Returns
    -------
    angular separation : `~astropy.units.Quantity` or float
        Type depends on input; `Quantity` in angular units, or float in
        radians.

    Notes
    -----
    The angular separation is calculated using the Vincenty formula [1]_,
    which is slightly more complex and computationally expensive than
    some alternatives, but is stable at at all distances, including the
    poles and antipodes.

    .. [1] http://en.wikipedia.org/wiki/Great-circle_distance
    """

    sdlon = np.sin(lon2 - lon1)
    cdlon = np.cos(lon2 - lon1)
    slat1 = np.sin(lat1)
    slat2 = np.sin(lat2)
    clat1 = np.cos(lat1)
    clat2 = np.cos(lat2)

    num1 = clat2 * sdlon
    num2 = clat1 * slat2 - slat1 * clat2 * cdlon
    denominator = slat1 * slat2 + clat1 * clat2 * cdlon

    return np.arctan2(np.hypot(num1, num2), denominator)


def position_angle(lon1, lat1, lon2, lat2):
    """
    Position Angle (East of North) between two points on a sphere.

    Parameters
    ----------
    lon1, lat1, lon2, lat2 : `Angle`, `~astropy.units.Quantity` or float
        Longitude and latitude of the two points. Quantities should be in
        angular units; floats in radians.

    Returns
    -------
    pa : `~astropy.coordinates.Angle`
        The (positive) position angle of the vector pointing from position 1 to
        position 2.  If any of the angles are arrays, this will contain an array
        following the appropriate `numpy` broadcasting rules.

    """
    from .angles import Angle

    deltalon = lon2 - lon1
    colat = np.cos(lat2)

    x = np.sin(lat2) * np.cos(lat1) - colat * np.sin(lat1) * np.cos(deltalon)
    y = np.sin(deltalon) * colat

    return Angle(np.arctan2(y, x), u.radian).wrap_at(360*u.deg)
'
]

{ #category : #sources }
PyProcessorTest >> codeOOP [
^
'class Foo(object):
    def getValue(self):
        return self.fibonacci(10)

    def fibonacci(self, n):
        if n < 2:
            return n
        else:
            return self.fibonacci(n - 1) + self.fibonacci(n - 2)
    
class Bar(Foo):
    def foo(self):
        return 42

if __name__ == ''__main__'':
    print(''Value = %d\n'' % (Foo().getValue()))
'
]

{ #category : #sources }
PyProcessorTest >> diff [
^
'# Licensed under a 3-clause BSD style license - see LICENSE.rst
"""
Facilities for diffing two FITS files.  Includes objects for diffing entire
FITS files, individual HDUs, FITS headers, or just FITS data.

Used to implement the fitsdiff program.
"""


import difflib
import fnmatch
import functools
import glob
import io
import operator
import os.path
import textwrap
import warnings

from collections import defaultdict
from functools import reduce
from itertools import islice

import numpy as np

from ... import __version__
from ...extern import six
from ...extern.six import u, string_types
from ...extern.six.moves import zip, range, map

from ...utils import indent
from ...utils.compat.funcsigs import signature
from .card import Card, BLANK_CARD
from .header import Header
from ...utils.decorators import deprecated_renamed_argument
# HDUList is used in one of the doctests
from .hdu.hdulist import fitsopen  # pylint: disable=W0611
from .hdu.table import _TableLikeHDU
from ...utils.exceptions import AstropyDeprecationWarning

__all__ = [''FITSDiff'', ''HDUDiff'', ''HeaderDiff'', ''ImageDataDiff'', ''RawDataDiff'',
           ''TableDataDiff'']

# Column attributes of interest for comparison
_COL_ATTRS = [(''unit'', ''units''), (''null'', ''null values''), (''bscale'', ''bscales''),
              (''bzero'', ''bzeros''), (''disp'', ''display formats''),
              (''dim'', ''dimensions'')]


# Smaller default shift-width for indent:
indent = functools.partial(indent, width=2)


class _BaseDiff(object):
    """
    Base class for all FITS diff objects.

    When instantiating a FITS diff object, the first two arguments are always
    the two objects to diff (two FITS files, two FITS headers, etc.).
    Instantiating a ``_BaseDiff`` also causes the diff itself to be executed.
    The returned ``_BaseDiff`` instance has a number of attribute that describe
    the results of the diff operation.

    The most basic attribute, present on all ``_BaseDiff`` instances, is
    ``.identical`` which is `True` if the two objects being compared are
    identical according to the diff method for objects of that type.
    """

    def __init__(self, a, b):
        """
        The ``_BaseDiff`` class does not implement a ``_diff`` method and
        should not be instantiated directly. Instead instantiate the
        appropriate subclass of ``_BaseDiff`` for the objects being compared
        (for example, use `HeaderDiff` to compare two `Header` objects.
        """

        self.a = a
        self.b = b

        # For internal use in report output
        self._fileobj = None
        self._indent = 0

        self._diff()

    def __nonzero__(self):
        """
        A ``_BaseDiff`` object acts as `True` in a boolean context if the two
        objects compared are identical.  Otherwise it acts as `False`.
        """

        return not self.identical

    if not six.PY2:
        __bool__ = __nonzero__
        del __nonzero__

    @classmethod
    def fromdiff(cls, other, a, b):
        """
        Returns a new Diff object of a specific subclass from an existing diff
        object, passing on the values for any arguments they share in common
        (such as ignore_keywords).

        For example::

            >>> from astropy.io import fits
            >>> hdul1, hdul2 = fits.HDUList(), fits.HDUList()
            >>> headera, headerb = fits.Header(), fits.Header()
            >>> fd = fits.FITSDiff(hdul1, hdul2, ignore_keywords=[''*''])
            >>> hd = fits.HeaderDiff.fromdiff(fd, headera, headerb)
            >>> list(hd.ignore_keywords)
            [''*'']
        """

        sig = signature(cls.__init__)
        # The first 3 arguments of any Diff initializer are self, a, and b.
        kwargs = {}
        for arg in list(sig.parameters.keys())[3:]:
            if hasattr(other, arg):
                kwargs[arg] = getattr(other, arg)

        return cls(a, b, **kwargs)

    @property
    def identical(self):
        """
        `True` if all the ``.diff_*`` attributes on this diff instance are
        empty, implying that no differences were found.

        Any subclass of ``_BaseDiff`` must have at least one ``.diff_*``
        attribute, which contains a non-empty value if and only if some
        difference was found between the two objects being compared.
        """

        return not any(getattr(self, attr) for attr in self.__dict__
                       if attr.startswith(''diff_''))

    @deprecated_renamed_argument(''clobber'', ''overwrite'', ''1.3'', pending=True)
    def report(self, fileobj=None, indent=0, overwrite=False):
        """
        Generates a text report on the differences (if any) between two
        objects, and either returns it as a string or writes it to a file-like
        object.

        Parameters
        ----------
        fileobj : file-like object, string, or None (optional)
            If `None`, this method returns the report as a string. Otherwise it
            returns `None` and writes the report to the given file-like object
            (which must have a ``.write()`` method at a minimum), or to a new
            file at the path specified.

        indent : int
            The number of 4 space tabs to indent the report.

        overwrite : bool, optional
            If ``True``, overwrite the output file if it exists. Raises an
            ``OSError`` (``IOError`` for Python 2) if ``False`` and the
            output file exists. Default is ``False``.

            .. versionchanged:: 1.3
               ``overwrite`` replaces the deprecated ``clobber`` argument.

        Returns
        -------
        report : str or None
        """

        return_string = False
        filepath = None

        if isinstance(fileobj, string_types):
            if os.path.exists(fileobj) and not overwrite:
                raise IOError("File {0} exists, aborting (pass in "
                              "overwrite=True to overwrite)".format(fileobj))
            else:
                filepath = fileobj
                fileobj = open(filepath, ''w'')
        elif fileobj is None:
            fileobj = io.StringIO()
            return_string = True

        self._fileobj = fileobj
        self._indent = indent  # This is used internally by _writeln

        try:
            self._report()
        finally:
            if filepath:
                fileobj.close()

        if return_string:
            return fileobj.getvalue()

    def _writeln(self, text):
        self._fileobj.write(indent(text, self._indent) + u(''\n''))

    def _diff(self):
        raise NotImplementedError

    def _report(self):
        raise NotImplementedError


class FITSDiff(_BaseDiff):
    """Diff two FITS files by filename, or two `HDUList` objects.

    `FITSDiff` objects have the following diff attributes:

    - ``diff_hdu_count``: If the FITS files being compared have different
      numbers of HDUs, this contains a 2-tuple of the number of HDUs in each
      file.

    - ``diff_hdus``: If any HDUs with the same index are different, this
      contains a list of 2-tuples of the HDU index and the `HDUDiff` object
      representing the differences between the two HDUs.
    """

    def __init__(self, a, b, ignore_keywords=[], ignore_comments=[],
                 ignore_fields=[], numdiffs=10, rtol=0.0, atol=0.0,
                 ignore_blanks=True, ignore_blank_cards=True, tolerance=None):
        """
        Parameters
        ----------
        a : str or `HDUList`
            The filename of a FITS file on disk, or an `HDUList` object.

        b : str or `HDUList`
            The filename of a FITS file on disk, or an `HDUList` object to
            compare to the first file.

        ignore_keywords : sequence, optional
            Header keywords to ignore when comparing two headers; the presence
            of these keywords and their values are ignored.  Wildcard strings
            may also be included in the list.

        ignore_comments : sequence, optional
            A list of header keywords whose comments should be ignored in the
            comparison.  May contain wildcard strings as with ignore_keywords.

        ignore_fields : sequence, optional
            The (case-insensitive) names of any table columns to ignore if any
            table data is to be compared.

        numdiffs : int, optional
            The number of pixel/table values to output when reporting HDU data
            differences.  Though the count of differences is the same either
            way, this allows controlling the number of different values that
            are kept in memory or output.  If a negative value is given, then
            numdiffs is treated as unlimited (default: 10).

        rtol : float, optional
            The relative difference to allow when comparing two float values
            either in header values, image arrays, or table columns
            (default: 0.0). Values which satisfy the expression

            .. math::

                \\left| a - b \\right| > \\text{atol} + \\text{rtol} \\cdot \\left| b \\right|

            are considered to be different.
            The underlying function used for comparison is `numpy.allclose`.

            .. versionchanged:: 2.0
               ``rtol`` replaces the deprecated ``tolerance`` argument.

        atol : float, optional
            The allowed absolute difference. See also ``rtol`` parameter.

            .. versionadded:: 2.0

        ignore_blanks : bool, optional
            Ignore extra whitespace at the end of string values either in
            headers or data. Extra leading whitespace is not ignored
            (default: True).

        ignore_blank_cards : bool, optional
            Ignore all cards that are blank, i.e. they only contain
            whitespace (default: True).
        """

        if isinstance(a, string_types):
            try:
                a = fitsopen(a)
            except Exception as exc:
                raise IOError("error opening file a ({}): {}: {}".format(
                        a, exc.__class__.__name__, exc.args[0]))
            close_a = True
        else:
            close_a = False

        if isinstance(b, string_types):
            try:
                b = fitsopen(b)
            except Exception as exc:
                raise IOError("error opening file b ({}): {}: {}".format(
                        b, exc.__class__.__name__, exc.args[0]))
            close_b = True
        else:
            close_b = False

        # Normalize keywords/fields to ignore to upper case
        self.ignore_keywords = set(k.upper() for k in ignore_keywords)
        self.ignore_comments = set(k.upper() for k in ignore_comments)
        self.ignore_fields = set(k.upper() for k in ignore_fields)

        self.numdiffs = numdiffs
        self.rtol = rtol
        self.atol = atol

        if tolerance is not None:  # This should be removed in the next astropy version
            warnings.warn(
                ''"tolerance" was deprecated in version 2.0 and will be removed in ''
                ''a future version. Use argument "rtol" instead.'',
                AstropyDeprecationWarning)
            self.rtol = tolerance  # when tolerance is provided *always* ignore `rtol`
                                   # during the transition/deprecation period

        self.ignore_blanks = ignore_blanks
        self.ignore_blank_cards = ignore_blank_cards

        self.diff_hdu_count = ()
        self.diff_hdus = []

        try:
            super(FITSDiff, self).__init__(a, b)
        finally:
            if close_a:
                a.close()
            if close_b:
                b.close()

    def _diff(self):
        if len(self.a) != len(self.b):
            self.diff_hdu_count = (len(self.a), len(self.b))

        # For now, just compare the extensions one by one in order...might
        # allow some more sophisticated types of diffing later...
        # TODO: Somehow or another simplify the passing around of diff
        # options--this will become important as the number of options grows
        for idx in range(min(len(self.a), len(self.b))):
            hdu_diff = HDUDiff.fromdiff(self, self.a[idx], self.b[idx])

            if not hdu_diff.identical:
                self.diff_hdus.append((idx, hdu_diff))

    def _report(self):
        wrapper = textwrap.TextWrapper(initial_indent=''  '',
                                       subsequent_indent=''  '')

        # print out heading and parameter values
        filenamea = self.a.filename()
        if not filenamea:
            filenamea = ''<{} object at {:#x}>''.format(self.a.__class__.__name__,
                                                      id(self.a))

        filenameb = self.b.filename()
        if not filenameb:
            filenameb = ''<{} object at {:#x}>''.format(self.b.__class__.__name__,
                                                      id(self.b))

        self._fileobj.write(u(''\n''))
        self._writeln(u('' fitsdiff: {}'').format(__version__))
        self._writeln(u('' a: {}\n b: {}'').format(filenamea, filenameb))
        if self.ignore_keywords:
            ignore_keywords = '' ''.join(sorted(self.ignore_keywords))
            self._writeln(u('' Keyword(s) not to be compared:\n{}'').format(
                    wrapper.fill(ignore_keywords)))

        if self.ignore_comments:
            ignore_comments = '' ''.join(sorted(self.ignore_comments))
            self._writeln(u('' Keyword(s) whose comments are not to be compared''
                            '':\n{}'').format(wrapper.fill(ignore_comments)))
        if self.ignore_fields:
            ignore_fields = '' ''.join(sorted(self.ignore_fields))
            self._writeln(u('' Table column(s) not to be compared:\n{}'').format(
                    wrapper.fill(ignore_fields)))
        self._writeln(u('' Maximum number of different data values to be ''
                        ''reported: {}'').format(self.numdiffs))
        self._writeln(u('' Relative tolerance: {},''
                        '' Absolute tolerance: {}'').format(self.rtol, self.atol))

        if self.diff_hdu_count:
            self._fileobj.write(u(''\n''))
            self._writeln(u(''Files contain different numbers of HDUs:''))
            self._writeln(u('' a: {}'').format(self.diff_hdu_count[0]))
            self._writeln(u('' b: {}'').format(self.diff_hdu_count[1]))

            if not self.diff_hdus:
                self._writeln(u(''No differences found between common HDUs.''))
                return
        elif not self.diff_hdus:
            self._fileobj.write(u(''\n''))
            self._writeln(u(''No differences found.''))
            return

        for idx, hdu_diff in self.diff_hdus:
            # print out the extension heading
            if idx == 0:
                self._fileobj.write(u(''\n''))
                self._writeln(u(''Primary HDU:''))
            else:
                self._fileobj.write(u(''\n''))
                self._writeln(u(''Extension HDU {}:'').format(idx))
            hdu_diff.report(self._fileobj, indent=self._indent + 1)


class HDUDiff(_BaseDiff):
    """
    Diff two HDU objects, including their headers and their data (but only if
    both HDUs contain the same type of data (image, table, or unknown).

    `HDUDiff` objects have the following diff attributes:

    - ``diff_extnames``: If the two HDUs have different EXTNAME values, this
      contains a 2-tuple of the different extension names.

    - ``diff_extvers``: If the two HDUS have different EXTVER values, this
      contains a 2-tuple of the different extension versions.

    - ``diff_extlevels``: If the two HDUs have different EXTLEVEL values, this
      contains a 2-tuple of the different extension levels.

    - ``diff_extension_types``: If the two HDUs have different XTENSION values,
      this contains a 2-tuple of the different extension types.

    - ``diff_headers``: Contains a `HeaderDiff` object for the headers of the
      two HDUs. This will always contain an object--it may be determined
      whether the headers are different through ``diff_headers.identical``.

    - ``diff_data``: Contains either a `ImageDataDiff`, `TableDataDiff`, or
      `RawDataDiff` as appropriate for the data in the HDUs, and only if the
      two HDUs have non-empty data of the same type (`RawDataDiff` is used for
      HDUs containing non-empty data of an indeterminate type).
    """

    def __init__(self, a, b, ignore_keywords=[], ignore_comments=[],
                 ignore_fields=[], numdiffs=10, rtol=0.0, atol=0.0,
                 ignore_blanks=True, ignore_blank_cards=True, tolerance=None):
        """
        See `FITSDiff` for explanations of the initialization parameters.
        """

        self.ignore_keywords = set(k.upper() for k in ignore_keywords)
        self.ignore_comments = set(k.upper() for k in ignore_comments)
        self.ignore_fields = set(k.upper() for k in ignore_fields)

        self.rtol = rtol
        self.atol = atol

        if tolerance is not None:  # This should be removed in the next astropy version
            warnings.warn(
                ''"tolerance" was deprecated in version 2.0 and will be removed in ''
                ''a future version. Use argument "rtol" instead.'',
                AstropyDeprecationWarning)
            self.rtol = tolerance  # when tolerance is provided *always* ignore `rtol`
                                   # during the transition/deprecation period

        self.numdiffs = numdiffs
        self.ignore_blanks = ignore_blanks

        self.diff_extnames = ()
        self.diff_extvers = ()
        self.diff_extlevels = ()
        self.diff_extension_types = ()
        self.diff_headers = None
        self.diff_data = None

        super(HDUDiff, self).__init__(a, b)

    def _diff(self):
        if self.a.name != self.b.name:
            self.diff_extnames = (self.a.name, self.b.name)

        if self.a.ver != self.b.ver:
            self.diff_extvers = (self.a.ver, self.b.ver)

        if self.a.level != self.b.level:
            self.diff_extlevels = (self.a.level, self.b.level)

        if self.a.header.get(''XTENSION'') != self.b.header.get(''XTENSION''):
            self.diff_extension_types = (self.a.header.get(''XTENSION''),
                                         self.b.header.get(''XTENSION''))

        self.diff_headers = HeaderDiff.fromdiff(self, self.a.header.copy(),
                                                self.b.header.copy())

        if self.a.data is None or self.b.data is None:
            # TODO: Perhaps have some means of marking this case
            pass
        elif self.a.is_image and self.b.is_image:
            self.diff_data = ImageDataDiff.fromdiff(self, self.a.data,
                                                    self.b.data)
        elif (isinstance(self.a, _TableLikeHDU) and
              isinstance(self.b, _TableLikeHDU)):
            # TODO: Replace this if/when _BaseHDU grows a .is_table property
            self.diff_data = TableDataDiff.fromdiff(self, self.a.data,
                                                    self.b.data)
        elif not self.diff_extension_types:
            # Don''t diff the data for unequal extension types that are not
            # recognized image or table types
            self.diff_data = RawDataDiff.fromdiff(self, self.a.data,
                                                  self.b.data)

    def _report(self):
        if self.identical:
            self._writeln(u(" No differences found."))
        if self.diff_extension_types:
            self._writeln(u(" Extension types differ:\n  a: {}\n  "
                            "b: {}").format(*self.diff_extension_types))
        if self.diff_extnames:
            self._writeln(u(" Extension names differ:\n  a: {}\n  "
                            "b: {}").format(*self.diff_extnames))
        if self.diff_extvers:
            self._writeln(u(" Extension versions differ:\n  a: {}\n  "
                            "b: {}").format(*self.diff_extvers))

        if self.diff_extlevels:
            self._writeln(u(" Extension levels differ:\n  a: {}\n  "
                            "b: {}").format(*self.diff_extlevels))

        if not self.diff_headers.identical:
            self._fileobj.write(u(''\n''))
            self._writeln(u(" Headers contain differences:"))
            self.diff_headers.report(self._fileobj, indent=self._indent + 1)

        if self.diff_data is not None and not self.diff_data.identical:
            self._fileobj.write(u(''\n''))
            self._writeln(u(" Data contains differences:"))
            self.diff_data.report(self._fileobj, indent=self._indent + 1)


class HeaderDiff(_BaseDiff):
    """
    Diff two `Header` objects.

    `HeaderDiff` objects have the following diff attributes:

    - ``diff_keyword_count``: If the two headers contain a different number of
      keywords, this contains a 2-tuple of the keyword count for each header.

    - ``diff_keywords``: If either header contains one or more keywords that
      don''t appear at all in the other header, this contains a 2-tuple
      consisting of a list of the keywords only appearing in header a, and a
      list of the keywords only appearing in header b.

    - ``diff_duplicate_keywords``: If a keyword appears in both headers at
      least once, but contains a different number of duplicates (for example, a
      different number of HISTORY cards in each header), an item is added to
      this dict with the keyword as the key, and a 2-tuple of the different
      counts of that keyword as the value.  For example::

          {''HISTORY'': (20, 19)}

      means that header a contains 20 HISTORY cards, while header b contains
      only 19 HISTORY cards.

    - ``diff_keyword_values``: If any of the common keyword between the two
      headers have different values, they appear in this dict.  It has a
      structure similar to ``diff_duplicate_keywords``, with the keyword as the
      key, and a 2-tuple of the different values as the value.  For example::

          {''NAXIS'': (2, 3)}

      means that the NAXIS keyword has a value of 2 in header a, and a value of
      3 in header b.  This excludes any keywords matched by the
      ``ignore_keywords`` list.

    - ``diff_keyword_comments``: Like ``diff_keyword_values``, but contains
      differences between keyword comments.

    `HeaderDiff` objects also have a ``common_keywords`` attribute that lists
    all keywords that appear in both headers.
    """

    def __init__(self, a, b, ignore_keywords=[], ignore_comments=[],
                 rtol=0.0, atol=0.0, ignore_blanks=True, ignore_blank_cards=True,
                 tolerance=None):
        """
        See `FITSDiff` for explanations of the initialization parameters.
        """

        self.ignore_keywords = set(k.upper() for k in ignore_keywords)
        self.ignore_comments = set(k.upper() for k in ignore_comments)

        self.rtol = rtol
        self.atol = atol

        if tolerance is not None:  # This should be removed in the next astropy version
            warnings.warn(
                ''"tolerance" was deprecated in version 2.0 and will be removed in ''
                ''a future version. Use argument "rtol" instead.'',
                AstropyDeprecationWarning)
            self.rtol = tolerance  # when tolerance is provided *always* ignore `rtol`
                                   # during the transition/deprecation period

        self.ignore_blanks = ignore_blanks
        self.ignore_blank_cards = ignore_blank_cards

        self.ignore_keyword_patterns = set()
        self.ignore_comment_patterns = set()
        for keyword in list(self.ignore_keywords):
            keyword = keyword.upper()
            if keyword != ''*'' and glob.has_magic(keyword):
                self.ignore_keywords.remove(keyword)
                self.ignore_keyword_patterns.add(keyword)
        for keyword in list(self.ignore_comments):
            keyword = keyword.upper()
            if keyword != ''*'' and glob.has_magic(keyword):
                self.ignore_comments.remove(keyword)
                self.ignore_comment_patterns.add(keyword)

        # Keywords appearing in each header
        self.common_keywords = []

        # Set to the number of keywords in each header if the counts differ
        self.diff_keyword_count = ()

        # Set if the keywords common to each header (excluding ignore_keywords)
        # appear in different positions within the header
        # TODO: Implement this
        self.diff_keyword_positions = ()

        # Keywords unique to each header (excluding keywords in
        # ignore_keywords)
        self.diff_keywords = ()

        # Keywords that have different numbers of duplicates in each header
        # (excluding keywords in ignore_keywords)
        self.diff_duplicate_keywords = {}

        # Keywords common to each header but having different values (excluding
        # keywords in ignore_keywords)
        self.diff_keyword_values = defaultdict(list)

        # Keywords common to each header but having different comments
        # (excluding keywords in ignore_keywords or in ignore_comments)
        self.diff_keyword_comments = defaultdict(list)

        if isinstance(a, string_types):
            a = Header.fromstring(a)
        if isinstance(b, string_types):
            b = Header.fromstring(b)

        if not (isinstance(a, Header) and isinstance(b, Header)):
            raise TypeError(''HeaderDiff can only diff astropy.io.fits.Header ''
                            ''objects or strings containing FITS headers.'')

        super(HeaderDiff, self).__init__(a, b)

    # TODO: This doesn''t pay much attention to the *order* of the keywords,
    # except in the case of duplicate keywords.  The order should be checked
    # too, or at least it should be an option.
    def _diff(self):
        if self.ignore_blank_cards:
            cardsa = [c for c in self.a.cards if str(c) != BLANK_CARD]
            cardsb = [c for c in self.b.cards if str(c) != BLANK_CARD]
        else:
            cardsa = list(self.a.cards)
            cardsb = list(self.b.cards)

        # build dictionaries of keyword values and comments
        def get_header_values_comments(cards):
            values = {}
            comments = {}
            for card in cards:
                value = card.value
                if self.ignore_blanks and isinstance(value, string_types):
                    value = value.rstrip()
                values.setdefault(card.keyword, []).append(value)
                comments.setdefault(card.keyword, []).append(card.comment)
            return values, comments

        valuesa, commentsa = get_header_values_comments(cardsa)
        valuesb, commentsb = get_header_values_comments(cardsb)

        # Normalize all keyword to upper-case for comparison''s sake;
        # TODO: HIERARCH keywords should be handled case-sensitively I think
        keywordsa = set(k.upper() for k in valuesa)
        keywordsb = set(k.upper() for k in valuesb)

        self.common_keywords = sorted(keywordsa.intersection(keywordsb))
        if len(cardsa) != len(cardsb):
            self.diff_keyword_count = (len(cardsa), len(cardsb))

        # Any other diff attributes should exclude ignored keywords
        keywordsa = keywordsa.difference(self.ignore_keywords)
        keywordsb = keywordsb.difference(self.ignore_keywords)
        if self.ignore_keyword_patterns:
            for pattern in self.ignore_keyword_patterns:
                keywordsa = keywordsa.difference(fnmatch.filter(keywordsa,
                                                                pattern))
                keywordsb = keywordsb.difference(fnmatch.filter(keywordsb,
                                                                pattern))

        if ''*'' in self.ignore_keywords:
            # Any other differences between keywords are to be ignored
            return

        left_only_keywords = sorted(keywordsa.difference(keywordsb))
        right_only_keywords = sorted(keywordsb.difference(keywordsa))

        if left_only_keywords or right_only_keywords:
            self.diff_keywords = (left_only_keywords, right_only_keywords)

        # Compare count of each common keyword
        for keyword in self.common_keywords:
            if keyword in self.ignore_keywords:
                continue
            if self.ignore_keyword_patterns:
                skip = False
                for pattern in self.ignore_keyword_patterns:
                    if fnmatch.fnmatch(keyword, pattern):
                        skip = True
                        break
                if skip:
                    continue

            counta = len(valuesa[keyword])
            countb = len(valuesb[keyword])
            if counta != countb:
                self.diff_duplicate_keywords[keyword] = (counta, countb)

            # Compare keywords'' values and comments
            for a, b in zip(valuesa[keyword], valuesb[keyword]):
                if diff_values(a, b, rtol=self.rtol, atol=self.atol):
                    self.diff_keyword_values[keyword].append((a, b))
                else:
                    # If there are duplicate keywords we need to be able to
                    # index each duplicate; if the values of a duplicate
                    # are identical use None here
                    self.diff_keyword_values[keyword].append(None)

            if not any(self.diff_keyword_values[keyword]):
                # No differences found; delete the array of Nones
                del self.diff_keyword_values[keyword]

            if ''*'' in self.ignore_comments or keyword in self.ignore_comments:
                continue
            if self.ignore_comment_patterns:
                skip = False
                for pattern in self.ignore_comment_patterns:
                    if fnmatch.fnmatch(keyword, pattern):
                        skip = True
                        break
                if skip:
                    continue

            for a, b in zip(commentsa[keyword], commentsb[keyword]):
                if diff_values(a, b):
                    self.diff_keyword_comments[keyword].append((a, b))
                else:
                    self.diff_keyword_comments[keyword].append(None)

            if not any(self.diff_keyword_comments[keyword]):
                del self.diff_keyword_comments[keyword]

    def _report(self):
        if self.diff_keyword_count:
            self._writeln(u('' Headers have different number of cards:''))
            self._writeln(u(''  a: {}'').format(self.diff_keyword_count[0]))
            self._writeln(u(''  b: {}'').format(self.diff_keyword_count[1]))
        if self.diff_keywords:
            for keyword in self.diff_keywords[0]:
                if keyword in Card._commentary_keywords:
                    val = self.a[keyword][0]
                else:
                    val = self.a[keyword]
                self._writeln(u('' Extra keyword {!r:8} in a: {!r}'').format(
                                keyword, val))
            for keyword in self.diff_keywords[1]:
                if keyword in Card._commentary_keywords:
                    val = self.b[keyword][0]
                else:
                    val = self.b[keyword]
                self._writeln(u('' Extra keyword {!r:8} in b: {!r}'').format(
                                keyword, val))

        if self.diff_duplicate_keywords:
            for keyword, count in sorted(self.diff_duplicate_keywords.items()):
                self._writeln(u('' Inconsistent duplicates of keyword ''
                                ''{!r:8}:'').format(keyword))
                self._writeln(u(''  Occurs {} time(s) in a, {} times ''
                                ''in (b)'').format(*count))

        if self.diff_keyword_values or self.diff_keyword_comments:
            for keyword in self.common_keywords:
                report_diff_keyword_attr(self._fileobj, ''values'',
                                         self.diff_keyword_values, keyword,
                                         ind=self._indent)
                report_diff_keyword_attr(self._fileobj, ''comments'',
                                         self.diff_keyword_comments, keyword,
                                         ind=self._indent)

# TODO: It might be good if there was also a threshold option for percentage of
# different pixels: For example ignore if only 1% of the pixels are different
# within some threshold.  There are lots of possibilities here, but hold off
# for now until specific cases come up.


class ImageDataDiff(_BaseDiff):
    """
    Diff two image data arrays (really any array from a PRIMARY HDU or an IMAGE
    extension HDU, though the data unit is assumed to be "pixels").

    `ImageDataDiff` objects have the following diff attributes:

    - ``diff_dimensions``: If the two arrays contain either a different number
      of dimensions or different sizes in any dimension, this contains a
      2-tuple of the shapes of each array.  Currently no further comparison is
      performed on images that don''t have the exact same dimensions.

    - ``diff_pixels``: If the two images contain any different pixels, this
      contains a list of 2-tuples of the array index where the difference was
      found, and another 2-tuple containing the different values.  For example,
      if the pixel at (0, 0) contains different values this would look like::

          [(0, 0), (1.1, 2.2)]

      where 1.1 and 2.2 are the values of that pixel in each array.  This
      array only contains up to ``self.numdiffs`` differences, for storage
      efficiency.

    - ``diff_total``: The total number of different pixels found between the
      arrays.  Although ``diff_pixels`` does not necessarily contain all the
      different pixel values, this can be used to get a count of the total
      number of differences found.

    - ``diff_ratio``: Contains the ratio of ``diff_total`` to the total number
      of pixels in the arrays.
    """

    def __init__(self, a, b, numdiffs=10, rtol=0.0, atol=0.0, tolerance=None):
        """
        See `FITSDiff` for explanations of the initialization parameters.
        """

        self.numdiffs = numdiffs
        self.rtol = rtol
        self.atol = atol

        if tolerance is not None:  # This should be removed in the next astropy version
            warnings.warn(
                ''"tolerance" was deprecated in version 2.0 and will be removed in ''
                ''a future version. Use argument "rtol" instead.'',
                AstropyDeprecationWarning)
            self.rtol = tolerance  # when tolerance is provided *always* ignore `rtol`
                                   # during the transition/deprecation period

        self.diff_dimensions = ()
        self.diff_pixels = []
        self.diff_ratio = 0

        # self.diff_pixels only holds up to numdiffs differing pixels, but this
        # self.diff_total stores the total count of differences between
        # the images, but not the different values
        self.diff_total = 0

        super(ImageDataDiff, self).__init__(a, b)

    def _diff(self):
        if self.a.shape != self.b.shape:
            self.diff_dimensions = (self.a.shape, self.b.shape)
            # Don''t do any further comparison if the dimensions differ
            # TODO: Perhaps we could, however, diff just the intersection
            # between the two images
            return

        # Find the indices where the values are not equal
        # If neither a nor b are floating point, ignore rtol and atol
        if not ((np.issubdtype(self.a.dtype, float) or
                 np.issubdtype(self.a.dtype, complex)) or
                (np.issubdtype(self.b.dtype, float) or
                 np.issubdtype(self.b.dtype, complex))):
            rtol = 0
            atol = 0
        else:
            rtol = self.rtol
            atol = self.atol

        diffs = where_not_allclose(self.a, self.b, atol=atol, rtol=rtol)

        self.diff_total = len(diffs[0])

        if self.diff_total == 0:
            # Then we''re done
            return

        if self.numdiffs < 0:
            numdiffs = self.diff_total
        else:
            numdiffs = self.numdiffs

        self.diff_pixels = [(idx, (self.a[idx], self.b[idx]))
                            for idx in islice(zip(*diffs), 0, numdiffs)]
        self.diff_ratio = float(self.diff_total) / float(len(self.a.flat))

    def _report(self):
        if self.diff_dimensions:
            dimsa = '' x ''.join(str(d) for d in
                               reversed(self.diff_dimensions[0]))
            dimsb = '' x ''.join(str(d) for d in
                               reversed(self.diff_dimensions[1]))
            self._writeln(u('' Data dimensions differ:''))
            self._writeln(u(''  a: {}'').format(dimsa))
            self._writeln(u(''  b: {}'').format(dimsb))
            # For now we don''t do any further comparison if the dimensions
            # differ; though in the future it might be nice to be able to
            # compare at least where the images intersect
            self._writeln(u('' No further data comparison performed.''))
            return

        if not self.diff_pixels:
            return

        for index, values in self.diff_pixels:
            index = [x + 1 for x in reversed(index)]
            self._writeln(u('' Data differs at {}:'').format(index))
            report_diff_values(self._fileobj, values[0], values[1],
                               ind=self._indent + 1)

        if self.diff_total > self.numdiffs:
            self._writeln(u('' ...''))
        self._writeln(u('' {} different pixels found ({:.2%} ''
                        ''different).'').format(self.diff_total,
                                              self.diff_ratio))



class RawDataDiff(ImageDataDiff):
    """
    `RawDataDiff` is just a special case of `ImageDataDiff` where the images
    are one-dimensional, and the data is treated as a 1-dimensional array of
    bytes instead of pixel values.  This is used to compare the data of two
    non-standard extension HDUs that were not recognized as containing image or
    table data.

    `ImageDataDiff` objects have the following diff attributes:

    - ``diff_dimensions``: Same as the ``diff_dimensions`` attribute of
      `ImageDataDiff` objects. Though the "dimension" of each array is just an
      integer representing the number of bytes in the data.

    - ``diff_bytes``: Like the ``diff_pixels`` attribute of `ImageDataDiff`
      objects, but renamed to reflect the minor semantic difference that these
      are raw bytes and not pixel values.  Also the indices are integers
      instead of tuples.

    - ``diff_total`` and ``diff_ratio``: Same as `ImageDataDiff`.
    """

    def __init__(self, a, b, numdiffs=10):
        """
        See `FITSDiff` for explanations of the initialization parameters.
        """

        self.diff_dimensions = ()
        self.diff_bytes = []

        super(RawDataDiff, self).__init__(a, b, numdiffs=numdiffs)

    def _diff(self):
        super(RawDataDiff, self)._diff()
        if self.diff_dimensions:
            self.diff_dimensions = (self.diff_dimensions[0][0],
                                    self.diff_dimensions[1][0])

        self.diff_bytes = [(x[0], y) for x, y in self.diff_pixels]
        del self.diff_pixels

    def _report(self):
        if self.diff_dimensions:
            self._writeln(u('' Data sizes differ:''))
            self._writeln(u(''  a: {} bytes'').format(self.diff_dimensions[0]))
            self._writeln(u(''  b: {} bytes'').format(self.diff_dimensions[1]))
            # For now we don''t do any further comparison if the dimensions
            # differ; though in the future it might be nice to be able to
            # compare at least where the images intersect
            self._writeln(u('' No further data comparison performed.''))
            return

        if not self.diff_bytes:
            return

        for index, values in self.diff_bytes:
            self._writeln(u('' Data differs at byte {}:'').format(index))
            report_diff_values(self._fileobj, values[0], values[1],
                               ind=self._indent + 1)

        self._writeln(u('' ...''))
        self._writeln(u('' {} different bytes found ({:.2%} ''
                        ''different).'').format(self.diff_total, self.diff_ratio))


class TableDataDiff(_BaseDiff):
    """
    Diff two table data arrays. It doesn''t matter whether the data originally
    came from a binary or ASCII table--the data should be passed in as a
    recarray.

    `TableDataDiff` objects have the following diff attributes:

    - ``diff_column_count``: If the tables being compared have different
      numbers of columns, this contains a 2-tuple of the column count in each
      table.  Even if the tables have different column counts, an attempt is
      still made to compare any columns they have in common.

    - ``diff_columns``: If either table contains columns unique to that table,
      either in name or format, this contains a 2-tuple of lists. The first
      element is a list of columns (these are full `Column` objects) that
      appear only in table a.  The second element is a list of tables that
      appear only in table b.  This only lists columns with different column
      definitions, and has nothing to do with the data in those columns.

    - ``diff_column_names``: This is like ``diff_columns``, but lists only the
      names of columns unique to either table, rather than the full `Column`
      objects.

    - ``diff_column_attributes``: Lists columns that are in both tables but
      have different secondary attributes, such as TUNIT or TDISP.  The format
      is a list of 2-tuples: The first a tuple of the column name and the
      attribute, the second a tuple of the different values.

    - ``diff_values``: `TableDataDiff` compares the data in each table on a
      column-by-column basis.  If any different data is found, it is added to
      this list.  The format of this list is similar to the ``diff_pixels``
      attribute on `ImageDataDiff` objects, though the "index" consists of a
      (column_name, row) tuple.  For example::

          [(''TARGET'', 0), (''NGC1001'', ''NGC1002'')]

      shows that the tables contain different values in the 0-th row of the
      ''TARGET'' column.

    - ``diff_total`` and ``diff_ratio``: Same as `ImageDataDiff`.

    `TableDataDiff` objects also have a ``common_columns`` attribute that lists
    the `Column` objects for columns that are identical in both tables, and a
    ``common_column_names`` attribute which contains a set of the names of
    those columns.
    """

    def __init__(self, a, b, ignore_fields=[], numdiffs=10, rtol=0.0, atol=0.0,
                 tolerance=None):
        """
        See `FITSDiff` for explanations of the initialization parameters.
        """

        self.ignore_fields = set(ignore_fields)
        self.numdiffs = numdiffs
        self.rtol = rtol
        self.atol = atol

        if tolerance is not None:  # This should be removed in the next astropy version
            warnings.warn(
                ''"tolerance" was deprecated in version 2.0 and will be removed in ''
                ''a future version. Use argument "rtol" instead.'',
                AstropyDeprecationWarning)
            self.rtol = tolerance  # when tolerance is provided *always* ignore `rtol`
                                   # during the transition/deprecation period

        self.common_columns = []
        self.common_column_names = set()

        # self.diff_columns contains columns with different column definitions,
        # but not different column data. Column data is only compared in
        # columns that have the same definitions
        self.diff_rows = ()
        self.diff_column_count = ()
        self.diff_columns = ()

        # If two columns have the same name+format, but other attributes are
        # different (such as TUNIT or such) they are listed here
        self.diff_column_attributes = []

        # Like self.diff_columns, but just contains a list of the column names
        # unique to each table, and in the order they appear in the tables
        self.diff_column_names = ()
        self.diff_values = []

        self.diff_ratio = 0
        self.diff_total = 0

        super(TableDataDiff, self).__init__(a, b)

    def _diff(self):
        # Much of the code for comparing columns is similar to the code for
        # comparing headers--consider refactoring
        colsa = self.a.columns
        colsb = self.b.columns

        if len(colsa) != len(colsb):
            self.diff_column_count = (len(colsa), len(colsb))

        # Even if the number of columns are unequal, we still do comparison of
        # any common columns
        colsa = dict((c.name.lower(), c) for c in colsa)
        colsb = dict((c.name.lower(), c) for c in colsb)

        if ''*'' in self.ignore_fields:
            # If all columns are to be ignored, ignore any further differences
            # between the columns
            return

        # Keep the user''s original ignore_fields list for reporting purposes,
        # but internally use a case-insensitive version
        ignore_fields = set([f.lower() for f in self.ignore_fields])

        # It might be nice if there were a cleaner way to do this, but for now
        # it''ll do
        for fieldname in ignore_fields:
            fieldname = fieldname.lower()
            if fieldname in colsa:
                del colsa[fieldname]
            if fieldname in colsb:
                del colsb[fieldname]

        colsa_set = set(colsa.values())
        colsb_set = set(colsb.values())
        self.common_columns = sorted(colsa_set.intersection(colsb_set),
                                     key=operator.attrgetter(''name''))

        self.common_column_names = set([col.name.lower()
                                        for col in self.common_columns])

        left_only_columns = dict((col.name.lower(), col)
                                 for col in colsa_set.difference(colsb_set))
        right_only_columns = dict((col.name.lower(), col)
                                  for col in colsb_set.difference(colsa_set))

        if left_only_columns or right_only_columns:
            self.diff_columns = (left_only_columns, right_only_columns)
            self.diff_column_names = ([], [])

        if left_only_columns:
            for col in self.a.columns:
                if col.name.lower() in left_only_columns:
                    self.diff_column_names[0].append(col.name)

        if right_only_columns:
            for col in self.b.columns:
                if col.name.lower() in right_only_columns:
                    self.diff_column_names[1].append(col.name)

        # If the tables have a different number of rows, we don''t compare the
        # columns right now.
        # TODO: It might be nice to optionally compare the first n rows where n
        # is the minimum of the row counts between the two tables.
        if len(self.a) != len(self.b):
            self.diff_rows = (len(self.a), len(self.b))
            return

        # If the tables contain no rows there''s no data to compare, so we''re
        # done at this point. (See ticket #178)
        if len(self.a) == len(self.b) == 0:
            return

        # Like in the old fitsdiff, compare tables on a column by column basis
        # The difficulty here is that, while FITS column names are meant to be
        # case-insensitive, PyFITS still allows, for the sake of flexibility,
        # two columns with the same name but different case.  When columns are
        # accessed in FITS tables, a case-sensitive is tried first, and failing
        # that a case-insensitive match is made.
        # It''s conceivable that the same column could appear in both tables
        # being compared, but with different case.
        # Though it *may* lead to inconsistencies in these rare cases, this
        # just assumes that there are no duplicated column names in either
        # table, and that the column names can be treated case-insensitively.
        for col in self.common_columns:
            name_lower = col.name.lower()
            if name_lower in ignore_fields:
                continue

            cola = colsa[name_lower]
            colb = colsb[name_lower]

            for attr, _ in _COL_ATTRS:
                vala = getattr(cola, attr, None)
                valb = getattr(colb, attr, None)
                if diff_values(vala, valb):
                    self.diff_column_attributes.append(
                        ((col.name.upper(), attr), (vala, valb)))

            arra = self.a[col.name]
            arrb = self.b[col.name]

            if (np.issubdtype(arra.dtype, float) and
                    np.issubdtype(arrb.dtype, float)):
                diffs = where_not_allclose(arra, arrb,
                                           rtol=self.rtol,
                                           atol=self.atol)
            elif ''P'' in col.format:
                diffs = ([idx for idx in range(len(arra))
                          if not np.allclose(arra[idx], arrb[idx],
                                             rtol=self.rtol,
                                             atol=self.atol)],)
            else:
                diffs = np.where(arra != arrb)

            self.diff_total += len(set(diffs[0]))

            if self.numdiffs >= 0:
                if len(self.diff_values) >= self.numdiffs:
                    # Don''t save any more diff values
                    continue

                # Add no more diff''d values than this
                max_diffs = self.numdiffs - len(self.diff_values)
            else:
                max_diffs = len(diffs[0])

            last_seen_idx = None
            for idx in islice(diffs[0], 0, max_diffs):
                if idx == last_seen_idx:
                    # Skip duplicate indices, which my occur when the column
                    # data contains multi-dimensional values; we''re only
                    # interested in storing row-by-row differences
                    continue
                last_seen_idx = idx
                self.diff_values.append(((col.name, idx),
                                         (arra[idx], arrb[idx])))

        total_values = len(self.a) * len(self.a.dtype.fields)
        self.diff_ratio = float(self.diff_total) / float(total_values)

    def _report(self):
        if self.diff_column_count:
            self._writeln(u('' Tables have different number of columns:''))
            self._writeln(u(''  a: {}'').format(self.diff_column_count[0]))
            self._writeln(u(''  b: {}'').format(self.diff_column_count[1]))

        if self.diff_column_names:
            # Show columns with names unique to either table
            for name in self.diff_column_names[0]:
                format = self.diff_columns[0][name.lower()].format
                self._writeln(u('' Extra column {} of format {} in a'').format(
                                name, format))
            for name in self.diff_column_names[1]:
                format = self.diff_columns[1][name.lower()].format
                self._writeln(u('' Extra column {} of format {} in b'').format(
                                name, format))

        col_attrs = dict(_COL_ATTRS)
        # Now go through each table again and show columns with common
        # names but other property differences...
        for col_attr, vals in self.diff_column_attributes:
            name, attr = col_attr
            self._writeln(u('' Column {} has different {}:'').format(
                    name, col_attrs[attr]))
            report_diff_values(self._fileobj, vals[0], vals[1],
                               ind=self._indent + 1)

        if self.diff_rows:
            self._writeln(u('' Table rows differ:''))
            self._writeln(u(''  a: {}'').format(self.diff_rows[0]))
            self._writeln(u(''  b: {}'').format(self.diff_rows[1]))
            self._writeln(u('' No further data comparison performed.''))
            return

        if not self.diff_values:
            return

        # Finally, let''s go through and report column data differences:
        for indx, values in self.diff_values:
            self._writeln(u('' Column {} data differs in row {}:'')
                          .format(*indx))
            report_diff_values(self._fileobj, values[0], values[1],
                               ind=self._indent + 1)

        if self.diff_values and self.numdiffs < self.diff_total:
            self._writeln(u('' ...{} additional difference(s) found.'').format(
                                (self.diff_total - self.numdiffs)))

        if self.diff_total > self.numdiffs:
            self._writeln(u('' ...''))

        self._writeln(u('' {} different table data element(s) found ''
                        ''({:.2%} different).'').format(self.diff_total,
                                                      self.diff_ratio))


def diff_values(a, b, rtol=0.0, atol=0.0):
    """
    Diff two scalar values.  If both values are floats they are compared to
    within the given absolute and relative tolerance.
    """

    if isinstance(a, float) and isinstance(b, float):
        if np.isnan(a) and np.isnan(b):
            return False
        return not np.allclose(a, b, rtol=rtol, atol=atol)
    else:
        return a != b


def report_diff_values(fileobj, a, b, ind=0):
    """Write a diff between two values to the specified file-like object."""

    typea = type(a)
    typeb = type(b)

    if (isinstance(a, string_types) and not isinstance(b, string_types)):
        a = repr(a).lstrip(''u'')
    elif (isinstance(b, string_types) and not isinstance(a, string_types)):
        b = repr(b).lstrip(''u'')

    if isinstance(a, (int, float, complex, np.number)):
        a = repr(a)

    if isinstance(b, (int, float, complex, np.number)):
        b = repr(b)

    if isinstance(a, np.ndarray) and isinstance(b, np.ndarray):
        diff_indices = np.where(a != b)
        num_diffs = reduce(operator.mul, map(len, diff_indices), 1)
        for idx in islice(zip(*diff_indices), 3):
            fileobj.write(indent(u(''  at {!r}:\n'').format(list(idx)), ind))
            report_diff_values(fileobj, a[idx], b[idx], ind=ind + 1)

        if num_diffs > 3:
            fileobj.write(indent(u(''  ...and at {} more indices.\n'').format(
                                        num_diffs - 3), ind))
        return

    padding = max(len(typea.__name__), len(typeb.__name__)) + 3

    for line in difflib.ndiff(str(a).splitlines(), str(b).splitlines()):
        if line[0] == ''-'':
            line = ''a>'' + line[1:]
            if typea != typeb:
                typename = ''('' + typea.__name__ + '') ''
                line = typename.rjust(padding) + line

        elif line[0] == ''+'':
            line = ''b>'' + line[1:]
            if typea != typeb:
                typename = ''('' + typeb.__name__ + '') ''
                line = typename.rjust(padding) + line
        else:
            line = '' '' + line
            if typea != typeb:
                line = '' '' * padding + line
        fileobj.write(indent(u(''  {}\n'').format(line.rstrip(''\n'')), ind))


def report_diff_keyword_attr(fileobj, attr, diffs, keyword, ind=0):
    """
    Write a diff between two header keyword values or comments to the specified
    file-like object.
    """

    if keyword in diffs:
        vals = diffs[keyword]
        for idx, val in enumerate(vals):
            if val is None:
                continue
            if idx == 0:
                dup = ''''
            else:
                dup = ''[{}]''.format(idx + 1)
            fileobj.write(indent(u('' Keyword {:8}{} has different {}:\n'').format(
                        keyword, dup, attr), ind))
            report_diff_values(fileobj, val[0], val[1], ind=ind + 1)


def where_not_allclose(a, b, rtol=1e-5, atol=1e-8):
    """
    A version of numpy.allclose that returns the indices where the two arrays
    differ, instead of just a boolean value.
    """

    # Create fixed mask arrays to handle INF and NaN; currently INF and NaN
    # are handled as equivalent
    if not np.all(np.isfinite(a)):
        a = np.ma.fix_invalid(a).data
    if not np.all(np.isfinite(b)):
        b = np.ma.fix_invalid(b).data

    if atol == 0.0 and rtol == 0.0:
        # Use a faster comparison for the most simple (and common) case
        return np.where(a != b)
    return np.where(np.abs(a - b) > (atol + rtol * np.abs(b)))
'
]

{ #category : #sources }
PyProcessorTest >> file01 [
	^ '
import random

guesses_made = 0

name = raw_input(''Hello! What is your name?\n'')

number = random.randint(1, 20)
print ''Well, {0}, I am thinking of a number between 1 and 20.''.format(name)

while guesses_made < 6:

    guess = int(raw_input(''Take a guess: ''))

    guesses_made += 1

    if guess < number:
        print ''Your guess is too low.''

    if guess > number:
        print ''Your guess is too high.''

    if guess == number:
        break

if guess == number:
    print ''Good job, {0}! You guessed my number in {1} guesses!''.format(name, guesses_made)
else:
    print ''Nope. The number I was thinking of was {0}''.format(number)
	'.
]

{ #category : #sources }
PyProcessorTest >> file02 [

	^ '# Author: Andreas Christian Mueller <t3kcit@gmail.com>
#
# (c) 2012
# Modified by: Paul Nechifor <paul@nechifor.net>
#
# License: MIT

from __future__ import division

import warnings
from random import Random
import os
import re
import sys
import colorsys
import numpy as np
from operator import itemgetter

from PIL import Image
from PIL import ImageColor
from PIL import ImageDraw
from PIL import ImageFont

from .query_integral_image import query_integral_image
from .tokenization import unigrams_and_bigrams, process_tokens

item1 = itemgetter(1)

FONT_PATH = os.environ.get("FONT_PATH", os.path.join(os.path.dirname(__file__),
                                                     "DroidSansMono.ttf"))
STOPWORDS = set([x.strip() for x in open(
    os.path.join(os.path.dirname(__file__), ''stopwords'')).read().split(''\n'')])


class IntegralOccupancyMap(object):
    def __init__(self, height, width, mask):
        self.height = height
        self.width = width
        if mask is not None:
            # the order of the cumsum''s is important for speed ?!
            self.integral = np.cumsum(np.cumsum(255 * mask, axis=1),
                                      axis=0).astype(np.uint32)
        else:
            self.integral = np.zeros((height, width), dtype=np.uint32)

    def sample_position(self, size_x, size_y, random_state):
        return query_integral_image(self.integral, size_x, size_y,
                                    random_state)

    def update(self, img_array, pos_x, pos_y):
        partial_integral = np.cumsum(np.cumsum(img_array[pos_x:, pos_y:],
                                               axis=1), axis=0)
        # paste recomputed part into old image
        # if x or y is zero it is a bit annoying
        if pos_x > 0:
            if pos_y > 0:
                partial_integral += (self.integral[pos_x - 1, pos_y:]
                                     - self.integral[pos_x - 1, pos_y - 1])
            else:
                partial_integral += self.integral[pos_x - 1, pos_y:]
        if pos_y > 0:
            partial_integral += self.integral[pos_x:, pos_y - 1][:, np.newaxis]

        self.integral[pos_x:, pos_y:] = partial_integral


def random_color_func(word=None, font_size=None, position=None,
                      orientation=None, font_path=None, random_state=None):
    """Random hue color generation.

    Default coloring method. This just picks a random hue with value 80% and
    lumination 50%.

    Parameters
    ----------
    word, font_size, position, orientation  : ignored.

    random_state : random.Random object or None, (default=None)
        If a random object is given, this is used for generating random
        numbers.

    """
    if random_state is None:
        random_state = Random()
    return "hsl(%d, 80%%, 50%%)" % random_state.randint(0, 255)


class colormap_color_func(object):
    """Color func created from matplotlib colormap.

    Parameters
    ----------
    colormap : string or matplotlib colormap
        Colormap to sample from

    Example
    -------
    >>> WordCloud(color_func=colormap_color_func("magma"))

    """
    def __init__(self, colormap):
        import matplotlib.pyplot as plt
        self.colormap = plt.cm.get_cmap(colormap)

    def __call__(self, word, font_size, position, orientation,
                 random_state=None, **kwargs):
        if random_state is None:
            random_state = Random()
        r, g, b, _ = 255 * np.array(self.colormap(random_state.uniform(0, 1)))
        return "rgb({:.0f}, {:.0f}, {:.0f})".format(r, g, b)


def get_single_color_func(color):
    """Create a color function which returns a single hue and saturation with.
    different values (HSV). Accepted values are color strings as usable by
    PIL/Pillow.

    >>> color_func1 = get_single_color_func(''deepskyblue'')
    >>> color_func2 = get_single_color_func(''#00b4d2'')
    """
    old_r, old_g, old_b = ImageColor.getrgb(color)
    rgb_max = 255.
    h, s, v = colorsys.rgb_to_hsv(old_r / rgb_max, old_g / rgb_max,
                                  old_b / rgb_max)

    def single_color_func(word=None, font_size=None, position=None,
                          orientation=None, font_path=None, random_state=None):
        """Random color generation.

        Additional coloring method. It picks a random value with hue and
        saturation based on the color given to the generating function.

        Parameters
        ----------
        word, font_size, position, orientation  : ignored.

        random_state : random.Random object or None, (default=None)
          If a random object is given, this is used for generating random
          numbers.

        """
        if random_state is None:
            random_state = Random()
        r, g, b = colorsys.hsv_to_rgb(h, s, random_state.uniform(0.2, 1))
        return ''rgb({:.0f}, {:.0f}, {:.0f})''.format(r * rgb_max, g * rgb_max,
                                                    b * rgb_max)
    return single_color_func


class WordCloud(object):
    """Word cloud object for generating and drawing.

    Parameters
    ----------
    font_path : string
        Font path to the font that will be used (OTF or TTF).
        Defaults to DroidSansMono path on a Linux machine. If you are on
        another OS or don''t have this font, you need to adjust this path.

    width : int (default=400)
        Width of the canvas.

    height : int (default=200)
        Height of the canvas.

    prefer_horizontal : float (default=0.90)
        The ratio of times to try horizontal fitting as opposed to vertical.

    mask : nd-array or None (default=None)
        If not None, gives a binary mask on where to draw words. If mask is not
        None, width and height will be ignored and the shape of mask will be
        used instead. All white (#FF or #FFFFFF) entries will be considerd
        "masked out" while other entries will be free to draw on. [This
        changed in the most recent version!]

    scale : float (default=1)
        Scaling between computation and drawing. For large word-cloud images,
        using scale instead of larger canvas size is significantly faster, but
        might lead to a coarser fit for the words.

    min_font_size : int (default=4)
        Smallest font size to use. Will stop when there is no more room in this
        size.

    font_step : int (default=1)
        Step size for the font. font_step > 1 might speed up computation but
        give a worse fit.

    max_words : number (default=200)
        The maximum number of words.

    stopwords : set of strings
        The words that will be eliminated.

    background_color : color value (default="black")
        Background color for the word cloud image.

    max_font_size : int or None (default=None)
        Maximum font size for the largest word. If None, height of the image is
        used.

    mode : string (default="RGB")
        Transparent background will be generated when mode is "RGBA" and
        background_color is None.

    relative_scaling : float (default=.5)
        Importance of relative word frequencies for font-size.  With
        relative_scaling=0, only word-ranks are considered.  With
        relative_scaling=1, a word that is twice as frequent will have twice
        the size.  If you want to consider the word frequencies and not only
        their rank, relative_scaling around .5 often looks good.

        .. versionchanged: 2.0
            Default is now 0.5.

    color_func : callable, default=None
        Callable with parameters word, font_size, position, orientation,
        font_path, random_state that returns a PIL color for each word.
        Overwrites "colormap".
        See colormap for specifying a matplotlib colormap instead.

    regexp : string or None (optional)
        Regular expression to split the input text into tokens in process_text.
        If None is specified, ``r"\w[\w'']+"`` is used.

    collocations : bool, default=True
        Whether to include collocations (bigrams) of two words.

        .. versionadded: 2.0

    colormap : string or matplotlib colormap, default="viridis"
        Matplotlib colormap to randomly draw colors from for each word.
        Ignored if "color_func" is specified.

        .. versionadded: 2.0

    Attributes
    ----------
    ``words_`` : dict of string to float
        Word tokens with associated frequency.

        .. versionchanged: 2.0
            ``words_`` is now a dictionary

    ``layout_`` : list of tuples (string, int, (int, int), int, color))
        Encodes the fitted word cloud. Encodes for each word the string, font
        size, position, orientation and color.

    Notes
    -----
    Larger canvases with make the code significantly slower. If you need a
    large word cloud, try a lower canvas size, and set the scale parameter.

    The algorithm might give more weight to the ranking of the words
    than their actual frequencies, depending on the ``max_font_size`` and the
    scaling heuristic.
    """

    def __init__(self, font_path=None, width=400, height=200, margin=2,
                 ranks_only=None, prefer_horizontal=.9, mask=None, scale=1,
                 color_func=None, max_words=200, min_font_size=4,
                 stopwords=None, random_state=None, background_color=''black'',
                 max_font_size=None, font_step=1, mode="RGB",
                 relative_scaling=.5, regexp=None, collocations=True,
                 colormap=None):
        if font_path is None:
            font_path = FONT_PATH
        if color_func is None and colormap is None:
            # we need a color map
            import matplotlib
            version = matplotlib.__version__
            if version[0] < "2" and version[2] < "5":
                colormap = "hsv"
            else:
                colormap = "viridis"
        self.colormap = colormap
        self.collocations = collocations
        self.font_path = font_path
        self.width = width
        self.height = height
        self.margin = margin
        self.prefer_horizontal = prefer_horizontal
        self.mask = mask
        self.scale = scale
        self.color_func = color_func or colormap_color_func(colormap)
        self.max_words = max_words
        self.stopwords = stopwords if stopwords is not None else STOPWORDS
        self.min_font_size = min_font_size
        self.font_step = font_step
        self.regexp = regexp
        if isinstance(random_state, int):
            random_state = Random(random_state)
        self.random_state = random_state
        self.background_color = background_color
        self.max_font_size = max_font_size
        self.mode = mode
        if relative_scaling < 0 or relative_scaling > 1:
            raise ValueError("relative_scaling needs to be "
                             "between 0 and 1, got %f." % relative_scaling)
        self.relative_scaling = relative_scaling
        if ranks_only is not None:
            warnings.warn("ranks_only is deprecated and will be removed as"
                          " it had no effect. Look into relative_scaling.",
                          DeprecationWarning)

    def fit_words(self, frequencies):
        """Create a word_cloud from words and frequencies.

        Alias to generate_from_frequencies.

        Parameters
        ----------
        frequencies : array of tuples
            A tuple contains the word and its frequency.

        Returns
        -------
        self
        """
        return self.generate_from_frequencies(frequencies)

    def generate_from_frequencies(self, frequencies, max_font_size=None):
        """Create a word_cloud from words and frequencies.

        Parameters
        ----------
        frequencies : dict from string to float
            A contains words and associated frequency.

        max_font_size : int
            Use this font-size instead of self.max_font_size

        Returns
        -------
        self

        """
        # make sure frequencies are sorted and normalized
        frequencies = sorted(frequencies.items(), key=item1, reverse=True)
        frequencies = frequencies[:self.max_words]
        # largest entry will be 1
        max_frequency = float(frequencies[0][1])

        frequencies = [(word, freq / max_frequency)
                       for word, freq in frequencies]

        if self.random_state is not None:
            random_state = self.random_state
        else:
            random_state = Random()

        if len(frequencies) <= 0:
            print("We need at least 1 word to plot a word cloud, got %d."
                  % len(frequencies))

        if self.mask is not None:
            mask = self.mask
            width = mask.shape[1]
            height = mask.shape[0]
            if mask.dtype.kind == ''f'':
                warnings.warn("mask image should be unsigned byte between 0"
                              " and 255. Got a float array")
            if mask.ndim == 2:
                boolean_mask = mask == 255
            elif mask.ndim == 3:
                # if all channels are white, mask out
                boolean_mask = np.all(mask[:, :, :3] == 255, axis=-1)
            else:
                raise ValueError("Got mask of invalid shape: %s"
                                 % str(mask.shape))
        else:
            boolean_mask = None
            height, width = self.height, self.width
        occupancy = IntegralOccupancyMap(height, width, boolean_mask)

        # create image
        img_grey = Image.new("L", (width, height))
        draw = ImageDraw.Draw(img_grey)
        img_array = np.asarray(img_grey)
        font_sizes, positions, orientations, colors = [], [], [], []

        last_freq = 1.

        if max_font_size is None:
            # if not provided use default font_size
            max_font_size = self.max_font_size

        if max_font_size is None:
            # figure out a good font size by trying to draw with
            # just the first two words
            if len(frequencies) == 1:
                # we only have one word. We make it big!
                font_size = self.height
            else:
                self.generate_from_frequencies(dict(frequencies[:2]),
                                               max_font_size=self.height)
                # find font sizes
                sizes = [x[1] for x in self.layout_]
                font_size = 2 * sizes[0] * sizes[1] / (sizes[0] + sizes[1])
        else:
            font_size = max_font_size

        # we set self.words_ here because we called generate_from_frequencies
        # above... hurray for good design?
        self.words_ = dict(frequencies)

        # start drawing grey image
        for word, freq in frequencies:
            # select the font size
            rs = self.relative_scaling
            if rs != 0:
                font_size = int(round((rs * (freq / float(last_freq))
                                       + (1 - rs)) * font_size))
            if random_state.random() < self.prefer_horizontal:
                orientation = None
            else:
                orientation = Image.ROTATE_90
            tried_other_orientation = False
            while True:
                # try to find a position
                font = ImageFont.truetype(self.font_path, font_size)
                # transpose font optionally
                transposed_font = ImageFont.TransposedFont(
                    font, orientation=orientation)
                # get size of resulting text
                box_size = draw.textsize(word, font=transposed_font)
                # find possible places using integral image:
                result = occupancy.sample_position(box_size[1] + self.margin,
                                                   box_size[0] + self.margin,
                                                   random_state)
                if result is not None or font_size < self.min_font_size:
                    # either we found a place or font-size went too small
                    break
                # if we didn''t find a place, make font smaller
                if tried_other_orientation is False:
                    orientation = (Image.ROTATE_90 if orientation is None else
                                   Image.ROTATE_90)
                    tried_other_orientation = True
                else:
                    font_size -= self.font_step
                    orientation = None

            if font_size < self.min_font_size:
                # we were unable to draw any more
                break

            x, y = np.array(result) + self.margin // 2
            # actually draw the text
            draw.text((y, x), word, fill="white", font=transposed_font)
            positions.append((x, y))
            orientations.append(orientation)
            font_sizes.append(font_size)
            colors.append(self.color_func(word, font_size=font_size,
                                          position=(x, y),
                                          orientation=orientation,
                                          random_state=random_state,
                                          font_path=self.font_path))
            # recompute integral image
            if self.mask is None:
                img_array = np.asarray(img_grey)
            else:
                img_array = np.asarray(img_grey) + boolean_mask
            # recompute bottom right
            # the order of the cumsum''s is important for speed ?!
            occupancy.update(img_array, x, y)
            last_freq = freq

        self.layout_ = list(zip(frequencies, font_sizes, positions,
                                orientations, colors))
        return self

    def process_text(self, text):
        """Splits a long text into words, eliminates the stopwords.

        Parameters
        ----------
        text : string
            The text to be processed.

        Returns
        -------
        words : dict (string, int)
            Word tokens with associated frequency.

        ..versionchanged:: 1.2.2
            Changed return type from list of tuples to dict.

        Notes
        -----
        There are better ways to do word tokenization, but I don''t want to
        include all those things.
        """

        stopwords = set(map(str.lower, self.stopwords))

        flags = (re.UNICODE if sys.version < ''3'' and type(text) is unicode
                 else 0)
        regexp = self.regexp if self.regexp is not None else r"\w[\w'']+"

        words = re.findall(regexp, text, flags)
        # remove stopwords
        words = [word for word in words if word.lower() not in stopwords]
        # remove ''s
        words = [word[:-2] if word.lower().endswith("''s") else word
                 for word in words]
        # remove numbers
        words = [word for word in words if not word.isdigit()]

        if self.collocations:
            word_counts = unigrams_and_bigrams(words)
        else:
            word_counts, _ = process_tokens(words)

        return word_counts

    def generate_from_text(self, text):
        """Generate wordcloud from text.

        Calls process_text and generate_from_frequencies.

        ..versionchanged:: 1.2.2
            Argument of generate_from_frequencies() is not return of
            process_text() any more.

        Returns
        -------
        self
        """
        words = self.process_text(text)
        self.generate_from_frequencies(words)
        return self

    def generate(self, text):
        """Generate wordcloud from text.

        Alias to generate_from_text.

        Calls process_text and generate_from_frequencies.

        Returns
        -------
        self
        """
        return self.generate_from_text(text)

    def _check_generated(self):
        """Check if ``layout_`` was computed, otherwise raise error."""
        if not hasattr(self, "layout_"):
            raise ValueError("WordCloud has not been calculated, call generate"
                             " first.")

    def to_image(self):
        self._check_generated()
        if self.mask is not None:
            width = self.mask.shape[1]
            height = self.mask.shape[0]
        else:
            height, width = self.height, self.width

        img = Image.new(self.mode, (int(width * self.scale),
                                    int(height * self.scale)),
                        self.background_color)
        draw = ImageDraw.Draw(img)
        for (word, count), font_size, position, orientation, color in self.layout_:
            font = ImageFont.truetype(self.font_path,
                                      int(font_size * self.scale))
            transposed_font = ImageFont.TransposedFont(
                font, orientation=orientation)
            pos = (int(position[1] * self.scale),
                   int(position[0] * self.scale))
            draw.text(pos, word, fill=color, font=transposed_font)
        return img

    def recolor(self, random_state=None, color_func=None, colormap=None):
        """Recolor existing layout.

        Applying a new coloring is much faster than generating the whole
        wordcloud.

        Parameters
        ----------
        random_state : RandomState, int, or None, default=None
            If not None, a fixed random state is used. If an int is given, this
            is used as seed for a random.Random state.

        color_func : function or None, default=None
            Function to generate new color from word count, font size, position
            and orientation.  If None, self.color_func is used.

        colormap : string or matplotlib colormap, default=None
            Use this colormap to generate new colors. Ignored if color_func
            is specified. If None, self.color_func (or self.color_map) is used.

        Returns
        -------
        self
        """
        if isinstance(random_state, int):
            random_state = Random(random_state)
        self._check_generated()

        if color_func is None:
            if colormap is None:
                color_func = self.color_func
            else:
                color_func = colormap_color_func(colormap)
        self.layout_ = [(word_freq, font_size, position, orientation,
                         color_func(word=word_freq[0], font_size=font_size,
                                    position=position, orientation=orientation,
                                    random_state=random_state,
                                    font_path=self.font_path))
                        for word_freq, font_size, position, orientation, _
                        in self.layout_]
        return self

    def to_file(self, filename):
        """Export to image file.

        Parameters
        ----------
        filename : string
            Location to write to.

        Returns
        -------
        self
        """

        img = self.to_image()
        img.save(filename)
        return self

    def to_array(self):
        """Convert to numpy array.

        Returns
        -------
        image : nd-array size (width, height, 3)
            Word cloud image as numpy matrix.
        """
        return np.array(self.to_image())

    def __array__(self):
        """Convert to numpy array.

        Returns
        -------
        image : nd-array size (width, height, 3)
            Word cloud image as numpy matrix.
        """
        return self.to_array()

    def to_html(self):
        raise NotImplementedError("FIXME!!!")
'
]

{ #category : #sources }
PyProcessorTest >> file03 [
"__init__.py"
	^ '
from .wordcloud import WordCloud, STOPWORDS, random_color_func, get_single_color_func
from .color_from_image import ImageColorGenerator

__all__ = [''WordCloud'', ''STOPWORDS'', ''random_color_func'', ''get_single_color_func'', ''ImageColorGenerator'']

'.
]

{ #category : #sources }
PyProcessorTest >> file04 [
"color_from_image.py"
	^ '
import numpy as np
from PIL import ImageFont


class ImageColorGenerator(object):
    """Color generator based on a color image.

    Generates colors based on an RGB image. A word will be colored using
    the mean color of the enclosing rectangle in the color image.

    After construction, the object acts as a callable that can be passed as
    color_func to the word cloud constructor or to the recolor method.

    Parameters
    ----------
    image : nd-array, shape (height, width, 3)
        Image to use to generate word colors. Alpha channels are ignored.
        This should be the same size as the canvas. for the wordcloud.
    """
    # returns the average color of the image in that region
    def __init__(self, image):
        if image.ndim not in [2, 3]:
            raise ValueError("ImageColorGenerator needs an image with ndim 2 or"
                             " 3, got %d" % image.ndim)
        if image.ndim == 3 and image.shape[2] not in [3, 4]:
            raise ValueError("A color image needs to have 3 or 4 channels, got %d"
                             % image.shape[2])
        self.image = image

    def __call__(self, word, font_size, font_path, position, orientation, **kwargs):
        """Generate a color for a given word using a fixed image."""
        # get the font to get the box size
        font = ImageFont.truetype(font_path, font_size)
        transposed_font = ImageFont.TransposedFont(font,
                                                   orientation=orientation)
        # get size of resulting text
        box_size = transposed_font.getsize(word)
        x = position[0]
        y = position[1]
        # cut out patch under word box
        patch = self.image[x:x + box_size[0], y:y + box_size[1]]
        if patch.ndim == 3:
            # drop alpha channel if any
            patch = patch[:, :, :3]
        if patch.ndim == 2:
            raise NotImplementedError("Gray-scale images TODO")
        color = np.mean(patch.reshape(-1, 3), axis=0)
        return "rgb(%d, %d, %d)" % tuple(color)

'.
]

{ #category : #sources }
PyProcessorTest >> file05 [
"tokenization.py"
	^ '
from itertools import tee
from operator import itemgetter
from collections import defaultdict
from math import log


def l(k, n, x):
    # dunning''s likelihood ratio with notation from
    # http://nlp.stanford.edu/fsnlp/promo/colloc.pdf
    return log(max(x, 1e-10)) * k + log(max(1 - x, 1e-10)) * (n - k)


def score(count_bigram, count1, count2, n_words):
    """Collocation score"""
    N = n_words
    c12 = count_bigram
    c1 = count1
    c2 = count2
    p = c2 / N
    p1 = c12 / c1
    p2 = (c2 - c12) / (N - c1)
    score = (l(c12, c1, p) + l(c2 - c12, N - c1, p)
             - l(c12, c1, p1) - l(c2 - c12, N - c1, p2))
    return -2 * score


def pairwise(iterable):
    # from itertool recipies
    # is -> (s0,s1), (s1,s2), (s2, s3), ...
    a, b = tee(iterable)
    next(b, None)
    return zip(a, b)


def unigrams_and_bigrams(words):
    n_words = len(words)
    # make tuples of two words following each other
    bigrams = list(pairwise(words))
    counts_unigrams = defaultdict(int)
    counts_bigrams = defaultdict(int)
    counts_unigrams, standard_form = process_tokens(words)
    counts_bigrams, standard_form_bigrams = process_tokens(
        [" ".join(bigram) for bigram in bigrams])
    # create a copy of counts_unigram so the score computation is not changed
    counts = counts_unigrams.copy()

    # decount words inside bigrams
    for bigram_string, count in counts_bigrams.items():
        bigram = tuple(bigram_string.split(" "))
        # collocation detection (30 is arbitrary):
        word1 = standard_form[bigram[0].lower()]
        word2 = standard_form[bigram[1].lower()]

        if score(count, counts[word1], counts[word2], n_words) > 30:
            counts_unigrams[word1] -= counts_bigrams[bigram_string]
            counts_unigrams[word2] -= counts_bigrams[bigram_string]
        # add joined bigram into unigrams
        counts_unigrams[bigram_string] = counts_bigrams[bigram_string]
    return counts_unigrams


def process_tokens(words):
    """Normalize cases and remove plurals.

    Each word is represented by the most common case.
    If a word appears with an "s" on the end and without an "s" on the end,
    the version with "s" is assumed to be a plural and merged with the
    version without "s".

    Parameters
    ----------
    words : iterable of strings
        Words to count.

    Returns
    -------
    counts : dict from string to int
        Counts for each unique word, with cases represented by the most common
        case, and plurals removed.

    standard_forms : dict from string to string
        For each lower-case word the standard capitalization.
    """
    # words can be either a list of unigrams or bigrams
    # d is a dict of dicts.
    # Keys of d are word.lower(). Values are dicts
    # counting frequency of each capitalization
    d = defaultdict(dict)
    for word in words:
        word_lower = word.lower()
        # get dict of cases for word_lower
        case_dict = d[word_lower]
        # increase this case
        case_dict[word] = case_dict.get(word, 0) + 1

    # merge plurals into the singular count (simple cases only)
    merged_plurals = {}
    for key in list(d.keys()):
        if key.endswith(''s''):
            key_singular = key[:-1]
            if key_singular in d:
                dict_plural = d[key]
                dict_singular = d[key_singular]
                for word, count in dict_plural.items():
                    singular = word[:-1]
                    dict_singular[singular] = (dict_singular.get(singular, 0)
                                               + count)
                merged_plurals[key] = key_singular
                del d[key]
    fused_cases = {}
    standard_cases = {}
    item1 = itemgetter(1)
    for word_lower, case_dict in d.items():
        # Get the most popular case.
        first = max(case_dict.items(), key=item1)[0]
        fused_cases[first] = sum(case_dict.values())
        standard_cases[word_lower] = first
    # add plurals to fused cases:
    for plural, singular in merged_plurals.items():
        standard_cases[plural] = standard_cases[singular.lower()]
    return fused_cases, standard_cases

'.
]

{ #category : #sources }
PyProcessorTest >> file06 [
"wordcloud_cli.py"
	^ '
#!/usr/bin/env python
# -*- coding: utf-8 -*-
r"""Command-line tool to generate word clouds
Usage::
    $ cat word.txt | wordcloud_cli.py

    $ wordcloud_cli.py --text=words.txt --stopwords=stopwords.txt
"""
import argparse
import wordcloud as wc
import numpy as np
import sys
from PIL import Image

def main(args):
    wordcloud = wc.WordCloud(stopwords=args.stopwords, mask=args.mask,
        width=args.width, height=args.height, font_path=args.font_path,
        margin=args.margin, relative_scaling=args.relative_scaling,
        color_func=args.color_func, background_color=args.background_color).generate(args.text)
    image = wordcloud.to_image()

    with args.imagefile:
        out = args.imagefile if sys.version < ''3'' else args.imagefile.buffer
        image.save(out, format=''png'')

def parse_args(arguments):
    prog = ''python wordcloud_cli.py''
    description = (''A simple command line interface for wordcloud module.'')
    parser = argparse.ArgumentParser(description=description)
    parser.add_argument(''--text'', metavar=''file'', type=argparse.FileType(), default=''-'',
        help=''specify file of words to build the word cloud (default: stdin)'')
    parser.add_argument(''--stopwords'', metavar=''file'', type=argparse.FileType(),
        help=''specify file of stopwords (containing one word per line) to remove from the given text after parsing'')
    parser.add_argument(''--imagefile'', metavar=''file'', type=argparse.FileType(''w''), default=''-'',
        help=''file the completed PNG image should be written to (default: stdout)'')
    parser.add_argument(''--fontfile'', metavar=''path'', dest=''font_path'',
        help=''path to font file you wish to use (default: DroidSansMono)'')
    parser.add_argument(''--mask'', metavar=''file'', type=argparse.FileType(),
        help=''mask to use for the image form'')
    parser.add_argument(''--colormask'', metavar=''file'', type=argparse.FileType(),
        help=''color mask to use for image coloring'')
    parser.add_argument(''--relative_scaling'', type=float, default=0,
        metavar=''rs'', help='' scaling of words by frequency (0 - 1)'')
    parser.add_argument(''--margin'', type=int, default=2,
        metavar=''width'', help=''spacing to leave around words'')
    parser.add_argument(''--width'', type=int, default=400,
        metavar=''width'', help=''define output image width'')
    parser.add_argument(''--height'', type=int, default=200,
        metavar=''height'', help=''define output image height'')
    parser.add_argument(''--color'', metavar=''color'',
        help=''use given color as coloring for the image - accepts any value from PIL.ImageColor.getcolor'')
    parser.add_argument(''--background'', metavar=''color'', default=''black'', type=str, dest=''background_color'',
        help=''use given color as background color for the image - accepts any value from PIL.ImageColor.getcolor'')
    args = parser.parse_args(arguments)

    if args.colormask and args.color:
        raise ValueError(''specify either a color mask or a color function'')

    with args.text:
        args.text = args.text.read()

    if args.stopwords:
        with args.stopwords:
            args.stopwords = set(map(str.strip, args.stopwords.readlines()))

    if args.mask:
        args.mask = np.array(Image.open(args.mask))

    color_func = wc.random_color_func
    if args.colormask:
        image = np.array(Image.open(args.colormask))
        color_func = wc.ImageColorGenerator(image)

    if args.color:
        color_func = wc.get_single_color_func(args.color)

    args.color_func = color_func
    return args

if __name__ == ''__main__'':
    main(parse_args(sys.argv[1:]))

'
]

{ #category : #sources }
PyProcessorTest >> printers [
^ 'from __future__ import print_function
from __future__ import absolute_import
from __future__ import division
from builtins import str
from builtins import range
from builtins import object
from past.builtins import long
import gdb
import math, re

try:
    debug
except:
    debug = False

import optparse
argparse = None                         # we''re using optparse

class GdbOptionParser(optparse.OptionParser):
    """A subclass of the standard optparse OptionParser for gdb

GdbOptionParser raises GdbError rather than exiting when asked for help, or
when given an illegal value. E.g.

parser = gdb.printing.GdbOptionParser("show image")
parser.add_option("-a", "--all", action="store_true",
                  help="Display the whole image")
parser.add_option("-w", "--width", type="int", default=8,
                  help="Field width for pixels")

opts, args =  parser.parse_args(args)
"""

    def __init__(self, prog, *args, **kwargs):
        """
Like optparse.OptionParser''s API, but with an initial command name argument
"""
        # OptionParser is an old-style class, so no super
        if not kwargs.get("prog"):
            kwargs["prog"] = prog
        optparse.OptionParser.__init__(self, *args, **kwargs)

    def parse_args(self, args, values=None):
        """Call OptionParser.parse_args after running gdb.string_to_argv"""
        if args is None:            # defaults to sys.argv
            args = ""
        try:
            args = gdb.string_to_argv(args)
        except TypeError:
            pass

        help = ("-h" in args or "--help" in args)
        opts, args = optparse.OptionParser.parse_args(self, args, values)
        opts.help = help
        if help:
            args = []

        return opts, args

    def exit(self, status=0, msg=""):
        """Raise GdbError rather than exiting"""
        if status == 0:
            if msg:
                print(msg, file=sys.stderr)
        else:
            raise gdb.GdbError(msg)

try:
    import gdb.printing

    class SharedPtrPrinter(object):
        "Print a shared_ptr"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            if self.val["px"]:
                return "shared_ptr(%s)" % self.val["px"].dereference()
            else:
                return "NULL"

    class GilPixelPrinter(object):
        "Print a boost::gil pixel"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            import pdb; pdb.set_trace()
            return self.val["_v0"]

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    def getEigenMatrixDimensions(val):
        m_storage = val["m_storage"]
        try:
            nx, ny = m_storage["m_cols"], m_storage["m_rows"]
        except gdb.error:           # only available for dynamic Matrices
            try:
                nx, ny = val.type.template_argument(1), val.type.template_argument(2)
            except RuntimeError:
                # should get dimens from template, but that''s gdb bug #11060
                size = m_storage["m_data"]["array"].type.sizeof
                size0 = m_storage["m_data"]["array"].dereference().type.sizeof
                # guess! Assume square
                nx = int(math.sqrt(size/size0))
                ny = size/(nx*size0)

        return nx, ny

    def getEigenValue(var, x, y=0):
        if re.search(r"Matrix", str(var.type)):
            if False:
                return var["operator()(int, int)"](x, y)

            NX, NY = getEigenMatrixDimensions(var)

            if x < 0 or x >= NX or y < 0 or y >= NY:
                raise gdb.GdbError("Element (%d, %d) is out of range 0:%d, 0:%d" %
                                   (x, y, NX - 1, NY - 1))

            m_data = var["m_storage"]["m_data"]
            if False:
                # convert to a pointer to the start of the array
                import pdb; pdb.set_trace()
                m_data = m_data.address.cast(m_data.type)

            try:
                val = m_data[x + y*NX]
            except:
                val = m_data["array"][x + y*NX]
        else:                       # Vector
            if False:
                return var["operator()(int)"](x)

            NX = getEigenMatrixDimensions(var)[0]

            if x < 0 or x >= NX:
                raise gdb.GdbError("Element (%d) is out of range 0:%d" % (x, NX - 1))

            m_data = var["m_storage"]["m_data"]

            if False:
                # convert to a pointer to the start of the array
                m_data = m_data.address.cast(m_data.type)

            try:
                val = m_data[x]
            except:
                val = m_data["array"][x]

        if val.type.code == gdb.TYPE_CODE_INT:
            val = int(val)
        elif val.type.code == gdb.TYPE_CODE_FLT:
            val = float(val)

        return val

    class EigenMatrixPrinter(object):
        "Print an Eigen Matrix"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            nx, ny = getEigenMatrixDimensions(self.val)

            return "%s{%dx%d}" % (self.val.type, nx, ny)

    class EigenVectorPrinter(object):
        "Print an Eigen Vector"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            m_storage = self.val["m_storage"]

            try:
                n = m_storage["n"]
            except gdb.error:           # only available for dynamic Matrices
                try:
                    n = m_storage.type.template_argument(1)
                except RuntimeError:
                    # should get dimens from template, but that''s gdb bug #11060
                    size = m_storage["m_data"]["array"].type.sizeof
                    size0 = m_storage["m_data"]["array"].dereference().type.sizeof
                    n = math.sqrt(size/size0)

            return "{%d}" % (n)

    class PrintEigenCommand(gdb.Command):
        """Print an eigen Matrix or Vector
    Usage: show eigen <matrix> [x0 y0 [nx ny]]
           show eigen <vector> [x0 [nx]]
    """

        def __init__ (self):
            super (PrintEigenCommand, self).__init__ ("show eigen",
                                                      gdb.COMMAND_DATA,
                                                      gdb.COMPLETE_SYMBOL)


        def _mget(self, var, x, y=0):
            return getEigenValue(var, x, y)

        def _vget(self, var, x):
            return getEigenValue(var, x)

        def invoke (self, args, fromTty):
            self.dont_repeat()

            parser = GdbOptionParser("show eigen")
            parser.add_option("-d", "--dataFmt", default="%.2f", help="Format for values")
            parser.add_option("-f", "--formatWidth", type="int", default=8, help="Field width for values")
            parser.add_option("-o", "--origin", type="str", nargs="+",
                                help="Origin of the part of the object to print")
            if False:
                parser.add_option("eigenObject", help="Expression giving Eigen::Matrix/Vector to show")
                parser.add_option("nx", help="Width of patch to print", type="int", default=0, nargs="?")
                parser.add_option("ny", help="Height of patch to print", type="int", default=0, nargs="?")

                opts =  parser.parse_args(args)
                if opts.help:
                    return
            else:
                (opts, args) = parser.parse_args(args)
                if opts.help:
                    return

                if not args:
                    raise gdb.GdbError("Please specify an object")
                opts.eigenObject = args.pop(0)

                opts.nx, opts.ny = 0, 0
                if args:
                    opts.nx = int(args.pop(0))
                if args:
                    opts.ny = int(args.pop(0))

                if args:
                    raise gdb.GdbError("Unrecognised trailing arguments: %s" % " ".join(args))

            var = gdb.parse_and_eval(opts.eigenObject)

            if not re.search(r"(Eigen|LinearTransform)::(Matrix|Vector)", str(var.type)):
                raise gdb.GdbError("Please specify an eigen matrix or vector, not %s" % var.type)

            if re.search(r"shared_ptr<", str(var.type)):
                var = var["px"].dereference()

            if var.type.code == gdb.TYPE_CODE_PTR:
                var = var.dereference()     # be nice

            isMatrix = re.search(r"Matrix", str(var.type))
            if isMatrix:
                NX, NY = getEigenMatrixDimensions(var)

                if opts.origin:
                    if len(opts.origin) != 2:
                        raise gdb.GdbError("Please specify both x0 and y0")

                    x0 = gdb.parse_and_eval(opts.origin[0])
                    y0 = gdb.parse_and_eval(opts.origin[1])
                else:
                    x0, y0 = 0, 0

                nx = opts.nx
                ny = opts.ny
                if nx == 0:
                    nx = NX
                if ny == 0:
                    ny = NY

                if nx == 1 and ny == 1:
                    print("%g" % self._vget(var, x0))
                    return
            else:
                NX = 0, var["m_storage"]["n"]

                if opts.origin:
                    if len(opts.origin) != 1:
                        raise gdb.GdbError("Please only specify x0")

                    x0 = gdb.parse_and_eval(opts.origin[0])
                else:
                    x0 = 0

                nx = opts.nx
                if nx == 0:
                    nx = NX

                if nx == 1:
                    print("%g" % self._vget(var, x0))
                    return
            #
            # OK, finally time to print
            #
            if isMatrix:
                print("%-4s" % "", end='' '')
                for x in range(x0, min(NX, x0 + nx)):
                    print("%*d" % (opts.formatWidth, x), end='' '')
                print("")

                for y in range(y0, min(NY, y0 + ny)):
                    print("%-4d" % y, end='' '')
                    for x in range(x0, min(NX, x0 + nx)):
                        print("%*s" % (opts.formatWidth, (opts.dataFmt % self._mget(var, x, y))), end='' '')
                    print("")
            else:
                for x in range(x0, min(NX, x0 + nx)):
                    print("%*s" % (opts.formatWidth, (opts.dataFmt % self._vget(var, x))), end='' '')
                print("")

    PrintEigenCommand()

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    class CitizenPrinter(object):
        "Print a Citizen"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            sentinel = long(self.val["_sentinel"].cast(gdb.lookup_type("unsigned int")))
            return "{%s %d 0x%x}" % (self.val.address, self.val["_CitizenId"], sentinel)

    class PrintCitizenCommand(gdb.Command):
        """Print a Citizen
    Usage: show citizen <obj>
    """

        def __init__ (self):
            super (PrintCitizenCommand, self).__init__ ("show citizen",
                                                        gdb.COMMAND_DATA,
                                                        gdb.COMPLETE_SYMBOL)

        def invoke (self, args, fromTty):
            self.dont_repeat()

            parser = GdbOptionParser("show citizen")
            if False:
                parser.add_option("object", help="The object in question")

                opts =  parser.parse_args(args)
                if opts.help:
                    return
            else:
                opts, args =  parser.parse_args(args)
                if opts.help:
                    return

                if not args:
                    raise gdb.GdbError("Please specify an object")
                opts.object = args.pop(0)

                if args:
                    raise gdb.GdbError("Unrecognised trailing arguments: %s" % " ".join(args))

            var = gdb.parse_and_eval(opts.object)
            if re.search(r"shared_ptr<", str(var.type)):
                var = var["px"]

            if var.type.code != gdb.TYPE_CODE_PTR:
                var = var.address

            citizen = var.dynamic_cast(gdb.lookup_type("lsst::daf::base::Citizen").pointer())

            if not citizen:
                raise gdb.GdbError("Failed to cast %s to Citizen -- is it a subclass?" % opts.object)

            citizen = citizen.dereference()

            print(citizen)

    PrintCitizenCommand()

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
    # afw

    class BaseSourceAttributesPrinter(object):
        "Print a BaseSourceAttributes"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            return "Base: {id=%d astrom=(%.3f, %.3f)}" % (self.val["_id"], self.val["_xAstrom"], self.val["_yAstrom"])

    class SourcePrinter(object):
        "Print a Source"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            return "Source{id=%d astrom=(%.3f, %.3f)}" % (self.val["_id"],
                                                          self.val["_xAstrom"], self.val["_yAstrom"])

    class DetectorPrinter(object):
        "Print a cameraGeom::Detector"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            return "Detector{name: %s id: %s type: %s bbox: %s}" % (self.val["_name"], self.val["_id"],
                self.val["_type"], self.val["_bbox"])

    class FootprintPrinter(object):
        "Print a Footprint"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            if False:
                nspan = self.val["_spans"]["size"]() # Fails (as its type is METHOD, not CODE)
            else:
                vec_impl = self.val["_spans"]["_M_impl"]
                nspan = vec_impl["_M_finish"] - vec_impl["_M_start"]

            return "Footprint{id=%d, nspan=%d, area=%d; BBox %s}" % (self.val["_fid"], nspan,
                                                                     self.val["_area"], self.val["_bbox"])

    class FootprintSetPrinter(object):
        "Print a FootprintSet"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            return "FootprintSet{%s; %s}" % (self.val["_region"], self.val["_footprints"])

    class PeakPrinter(object):
        "Print a Peak"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            return "Peak{%d, (%.2f, %.2f)}" % (self.val["_id"], self.val["_fx"], self.val["_fy"])

    class PsfPrinter(object):
        "Print a Psf"

        def to_string(self):
            return "%s" % (self.typeName())

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    class Box2Printer(object):
        "Print a Box2"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            # Make sure &foo works, too.
            type = self.val.type
            if type.code == gdb.TYPE_CODE_REF:
                type = type.target ()

            llc = [getEigenValue(self.val["_minimum"]["_vector"], i) for i in range(2)]
            dims = [getEigenValue(self.val["_dimensions"]["_vector"], i) for i in range(2)]

            return "Box2{(%s,%s)--(%s,%s)}" % (llc[0], llc[1],
                                               llc[0] + dims[0] - 1, llc[1] + dims[1] - 1)

        def display_hint (self):
            return "array"

    class CoordinateBasePrinter(object):
        "Print a CoordinateBase"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            return self.val["_vector"]["m_storage"]["m_data"]["array"]

        def display_hint (self):
            return "array"

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    class AxesPrinter(object):
        "Print an ellipse::Axes"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            vec = self.val["_vector"]
            return "[%g, %g, %g]" % (getEigenValue(vec, 0), getEigenValue(vec, 1), getEigenValue(vec, 2))

    class QuadrupolePrinter(object):
        "Print an ellipse::Quadrupole"

        def __init__(self, val):
            self.val = val

        def to_string(self):
            mat = self.val["_matrix"]

            if False:
                return mat
            else:
                return "[[%g, %g], [%g, %g]]" % (getEigenValue(mat, 0, 0), getEigenValue(mat, 0, 1),
                                                 getEigenValue(mat, 1, 0), getEigenValue(mat, 1, 1))

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    class ImagePrinter(object):
        "Print an ImageBase or derived class"

        def dimenStr(self, val=None):
            if val is None:
                val = self.val

            # Make sure &foo works, too.
            type = val.type
            if type.code == gdb.TYPE_CODE_REF:
                type = type.target()

            gilView = val["_gilView"]
            arr = val["_origin"]["_vector"]["m_storage"]["m_data"]["array"]

            x0, y0 = arr[0], arr[1]
            return "%dx%d%s%d%s%d" % (
                #val["getWidth"](), val["getHeight"](),
                gilView["_dimensions"]["x"], gilView["_dimensions"]["y"],
                ["", "+"][x0 >= 0], x0, # i.e. "+" if x0 >= 0 else "" in python >= 2.5
                ["", "+"][y0 >= 0], y0)

        def typeName(self):
            return self.typename.split(":")[-1]

        def __init__(self, val):
            self.typename = str(val.type)
            self.val = val

        def to_string(self):
            return "%s(%s)" % (self.typeName(), self.dimenStr())

    class MaskedImagePrinter(ImagePrinter):
        "Print a MaskedImage"

        def to_string(self):
            return "%s(%s)" % (self.typeName(), self.dimenStr(self.val["_image"]["px"].dereference()))

    class ExposurePrinter(ImagePrinter):
        "Print an Exposure"

        def to_string(self):
            return "%s(%s)" % (self.typeName(),
                               self.dimenStr(self.val["_maskedImage"]["_image"]["px"].dereference()))

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    class PrintImageCommand(gdb.Command):
        """Print an Image"""

        def __init__ (self):
            super (PrintImageCommand, self).__init__ ("show image",
                                                      gdb.COMMAND_DATA,
                                                      gdb.COMPLETE_SYMBOL)

        def get(self, var, x, y):
            if False:
                return var["operator()(int, int, bool)"](x, y, True)
            else:
                dimensions = var["_gilView"]["_dimensions"]
                if x < 0 or x >= dimensions["x"] or y < 0 or y >= dimensions["y"]:
                    raise gdb.GdbError("Pixel (%d, %d) is out of range 0:%d, 0:%d" %
                                       (x, y, dimensions["x"] - 1, dimensions["y"] - 1))

                pixels = var["_gilView"]["_pixels"]["_p"]
                step = pixels["_step_fn"]["_step"]/var.type.template_argument(0).sizeof

                return pixels["m_iterator"][x + y*step]["_v0"]

        def invoke (self, args, fromTty):
            self.dont_repeat()

            parser = GdbOptionParser("show image" + ("" if argparse else " <image> [<nx> [<ny>]]"))
            parser.add_option("-a", "--all", action="store_true", help="Display the whole image/mask")
            parser.add_option("-c", "--center", type="str", nargs=2, default=(None, None,),
                              help="Center the output at (x, y)")
            parser.add_option("-o", "--origin", type="str", nargs=2, default=(None, None,),
                                help="Print the region starting at (x, y)")
            parser.add_option("-x", "--xy0", action="store_true", help="Obey the image''s (x0, y0)")
            parser.add_option("-f", "--formatWidth", type="int", default=8, help="Field width for values")
            parser.add_option("-d", "--dataFmt", default="%.2f", help="Format for values")

            if argparse:
                parser.add_option("image", help="Expression giving image to show")
                parser.add_option("width", help="Width of patch to print", default=1, nargs="?")
                parser.add_option("height", help="Height of patch to print", default=1, nargs="?")

                opts =  parser.parse_args(args)
                if opts.help:
                    return
            else:
                opts, args =  parser.parse_args(args)
                if opts.help:
                    return

                if not args:
                    raise gdb.GdbError("Please specify an image")

                opts.image = args.pop(0)

                opts.width, opts.height = 1, 1
                if args:
                    opts.width = int(args.pop(0))
                if args:
                    opts.height = int(args.pop(0))

                if args:
                    raise gdb.GdbError("Unrecognised trailing arguments: %s" % " ".join(args))

            for i in range(2):
                val = "0"
                if opts.origin[i] is None:
                    if opts.center[i] is not None:
                        val = opts.center[i]
                else:
                    val = opts.origin[i]
                    if opts.center[i] is not None:
                        raise gdb.GdbError("You may not specify both --center and --origin")

                val = gdb.parse_and_eval(val)
                if i == 0: x0 = val
                else: y0 = val

            if opts.all:
                nx, ny = 0, 0
            else:
                nx, ny = opts.width, opts.height

            var = gdb.parse_and_eval(opts.image)

            if re.search(r"shared_ptr<", str(var.type)):
                var = var["px"].dereference()

            if not re.search(r"(lsst::afw::image::)?(Image|Mask|MaskedImage)", str(var.type.unqualified())):
                raise gdb.GdbError("Please specify an image, not %s" % var.type)

            if re.search(r"MaskedImage", str(var.type)) and \
                    not re.search(r"::Image(\s*&)?$", str(var.type)):
                print("N.b. %s is a MaskedImage; showing image" % (opts.image))
                var = var["_image"]

            if re.search(r"shared_ptr<", str(var.type)):
                var = var["px"].dereference()

            if var.type.code == gdb.TYPE_CODE_PTR:
                var = var.dereference()     # be nice

            pixelTypeName = str(var.type.template_argument(0))
            if opts.dataFmt:
                dataFmt = opts.dataFmt
            elif pixelTypeName in ["short", "unsigned short"]:
                dataFmt = "0x%x"
            elif pixelTypeName in ["int", "unsigned int"]:
                dataFmt = "%d"
            else:
                dataFmt = "%.2f"

            if nx == 0:
                nx = var["_gilView"]["_dimensions"]["x"]
            if ny == 0:
                ny = var["_gilView"]["_dimensions"]["y"]

            if opts.center[0]:
                x0 -= nx//2
                y0 -= ny//2

            if opts.xy0 and not opts.all:
                arr = var["_origin"]["_vector"]["m_storage"]["m_data"]["array"]

                x0 -= arr[0]
                y0 -= arr[1]
            #
            # OK, finally time to print
            #
            print("%-4s" % "", end='' '')
            for x in range(x0, x0 + nx):
                print("%*d" % (opts.formatWidth, x), end='' '')
            print("")

            for y in reversed(list(range(y0, y0 + ny))):
                print("%-4d" % y, end='' '')
                for x in range(x0, x0 + nx):
                    print("%*s" % (opts.formatWidth, dataFmt % self.get(var, x, y)), end='' '')
                print("")

    PrintImageCommand()

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    class BackgroundPrinter(object):
        "Print a Background"

        def __init__(self, val):
            self.typename = str(val.type)
            self.val = val

        def to_string(self):
            return "Background(%dx%d) %s %s" % (
                self.val["_imgWidth"], self.val["_imgHeight"],
                self.val["_bctrl"])

    class BackgroundControlPrinter(object):
        "Print a BackgroundControl"

        def __init__(self, val):
            self.typename = str(val.type)
            self.val = val

        def to_string(self):
            return "{%s %s %s %s}" % (re.sub(r"lsst::afw::math::Interpolate::", "", str(self.val["_style"])),
                                        re.sub(r"lsst::afw::math::", "", str(self.val["_prop"])),
                                        re.sub(r"lsst::afw::math::", "", str(self.val["_undersampleStyle"])),
                                        self.val["_sctrl"]["px"].dereference())

    class KernelPrinter(object):
        "Print a Kernel"

        def __init__(self, val):
            self.typename = str(val.type)
            self.val = val

        def to_string(self):
            return "%s(%dx%d)" % (self.typename,
                                  self.val["_width"], self.val["_height"])



    class StatisticsControlPrinter(object):
        "Print a StatisticsControl"

        def __init__(self, val):
            self.typename = str(val.type)
            self.val = val

        def to_string(self):
            return "{nSigma=%g nIter=%d ignore=0x%x}" % (self.val["_numSigmaClip"],
                                                         self.val["_numIter"],
                                                         self.val["_andMask"])

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    class TablePrinter(object):
        "Print a table::Table"

        def __init__(self, val):
            self.typename = str(val.type)
            self.val = val

        def to_string(self):
            return "{schema = %s, md=%s}" % (self.val["_schema"], self.val["_metadata"])

    class TableSchemaPrinter(object):
        "Print a table::Schema"

        def __init__(self, val):
            self.typename = str(val.type)
            self.val = val

        def to_string(self):
            names = str(self.val["_impl"]["px"]["_names"])
            names = re.sub(r"^[^{]*{|}|[\[\]\"\"]|\s*=\s*[^,]*", "", names)

            return "%s" % (names)

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    printers = []

    def register(obj=None):
        "Register my pretty-printers with objfile Obj."

        if obj is None:
            obj = gdb

        for p in printers:
            gdb.printing.register_pretty_printer(obj, p, replace=True)

    #-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    def build_boost_dictionary():
        """Surely this must be somewhere standard?"""

        printer = gdb.printing.RegexpCollectionPrettyPrinter("rhl-boost")

        printer.add_printer(''boost::shared_ptr'',
                            ''^(boost|tr1|std)::shared_ptr'', SharedPtrPrinter)
        printer.add_printer(''boost::gil::pixel'',
                            ''boost::gil::.*pixel_t'', GilPixelPrinter)

        return printer

    printers.append(build_boost_dictionary())

    def build_eigen_dictionary():
        """Surely this must be somewhere standard?"""

        printer = gdb.printing.RegexpCollectionPrettyPrinter("rhl-eigen")

        printer.add_printer(''eigen::Matrix'',
                            ''^Eigen::Matrix'', EigenMatrixPrinter)
        printer.add_printer(''eigen::Vector'',
                            ''^Eigen::Vector'', EigenVectorPrinter)

        return printer

    printers.append(build_eigen_dictionary())

#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

    def build_afw_dictionary():
        printer = gdb.printing.RegexpCollectionPrettyPrinter("afw")

        printer.add_printer(''lsst::afw::cameraGeom::Detector'',
                            ''^lsst::afw::cameraGeom::(Amp|Ccd|Detector|DetectorMosaic)$'', DetectorPrinter)

        printer.add_printer(''lsst::afw::detection::Footprint'',
                            ''^lsst::afw::detection::Footprint$'', FootprintPrinter)
        printer.add_printer(''lsst::afw::detection::FootprintSet'',
                            ''^lsst::afw::detection::FootprintSet'', FootprintSetPrinter)
        printer.add_printer(''lsst::afw::detection::Peak'',
                            ''^lsst::afw::detection::Peak$'', PeakPrinter)
        printer.add_printer(''lsst::afw::detection::Psf'',
                            ''^lsst::afw::detection::Psf$'', PsfPrinter)
        printer.add_printer(''lsst::afw::detection::Source'',
                            ''^lsst::afw::detection::Source$'', SourcePrinter)
        printer.add_printer(''lsst::afw::detection::BaseSourceAttributes'',
                            ''^lsst::afw::detection::BaseSourceAttributes$'', BaseSourceAttributesPrinter)

        printer.add_printer(''lsst::afw::geom::Box'',
                            ''^lsst::afw::geom::Box'', Box2Printer)
        printer.add_printer(''lsst::afw::geom::Extent'',
                            ''^lsst::afw::geom::Extent'', CoordinateBasePrinter)
        printer.add_printer(''lsst::afw::geom::Point'',
                            ''^lsst::afw::geom::Point'', CoordinateBasePrinter)

        printer.add_printer(''lsst::afw::geom::ellipses::Axes'',
                            ''^lsst::afw::geom::ellipses::Axes'', AxesPrinter)
        printer.add_printer(''lsst::afw::geom::ellipses::Quadrupole'',
                            ''^lsst::afw::geom::ellipses::Quadrupole'', QuadrupolePrinter)

        printer.add_printer(''lsst::afw::image::ImageBase'',
                            ''lsst::afw::image::ImageBase<[^>]+>$'', ImagePrinter)
        printer.add_printer(''lsst::afw::image::Image'',
                            ''lsst::afw::image::Image<[^>]+>$'', ImagePrinter)
        printer.add_printer(''lsst::afw::image::Mask'',
                            ''^lsst::afw::image::Mask<[^>]+>$'', ImagePrinter)
        printer.add_printer(''lsst::afw::image::MaskedImage'',
                            ''^lsst::afw::image::MaskedImage<[^>]+>$'', MaskedImagePrinter)
        printer.add_printer(''lsst::afw::image::Exposure'',
                            ''^lsst::afw::image::Exposure'', ExposurePrinter)

        printer.add_printer(''lsst::afw::math::Background'',
                            ''^lsst::afw::math::Background$'', BackgroundPrinter)
        printer.add_printer(''lsst::afw::math::BackgroundControl'',
                            ''^lsst::afw::math::BackgroundControl$'', BackgroundControlPrinter)
        printer.add_printer(''lsst::afw::math::Kernel'',
                            ''^lsst::afw::math::.*Kernel'', KernelPrinter)
        printer.add_printer(''lsst::afw::math::StatisticsControl'',
                            ''^lsst::afw::math::StatisticsControl'', StatisticsControlPrinter)

        printer.add_printer(''lsst::afw::table::Table'',
                            ''^lsst::afw::table::.*Table$'', TablePrinter)
        printer.add_printer(''lsst::afw::table::Schema'',
                            ''^lsst::afw::table::Schema$'', TableSchemaPrinter)

        return printer

    printers.append(build_afw_dictionary())

    def build_daf_base_dictionary():
        printer = gdb.printing.RegexpCollectionPrettyPrinter("daf::base")

        printer.add_printer(''lsst::daf::base::Citizen'',
                            ''lsst::daf::base::Citizen'', CitizenPrinter)

        return printer

    printers.append(build_daf_base_dictionary())
except ImportError as e:
    print("RHL", e)
    from .printers_oldgdb import *
'
]

{ #category : #initialization }
PyProcessorTest >> setUp [
	p := PyProcessor new.
]

{ #category : #tests }
PyProcessorTest >> testBasic [
	| f |
	self assert: p numberOfFiles equals: 0.
	p processFileAsString: self file01 named: 'foo.py'.
	self assert: p numberOfFiles equals: 1.

	f := p files anyOne.
	self assert: f loc equals: self file01 lines size.
	self assert: f importedFilenames equals: #('random').
	self assert: f baseFilenameWithoutExtension equals: 'foo'.
	self assert: f baseFilename equals: 'foo.py'.
]

{ #category : #tests }
PyProcessorTest >> testBasic02 [
	| f |
	self assert: p numberOfFiles equals: 0.
	p processFileAsString: self file02 named: 'wordcloud.py'.
	self assert: p numberOfFiles equals: 1.

	f := p files anyOne.
	self assert: f loc equals: self file02 lines size.
	self assert: f importedFilenames equals: #('warnings' 'os' 're' 'sys' 'colorsys' 'numpy' '__future__' 'random' 'operator' 'PIL' '.query_integral_image' '.tokenization').
	self assert: f baseFilenameWithoutExtension equals: 'wordcloud'.
	self assert: f baseFilename equals: 'wordcloud.py'.
]

{ #category : #tests }
PyProcessorTest >> testBasic03 [
	| m1 m2 |
	p processFileAsString: self file02 named: 'wordcloud.py'.
	p processFileAsString: self file03 named: '__init__.py'.
	p processFileAsString: self file04 named: 'color_from_image.py'.
	p processFileAsString: self file05 named: 'tokenization.py'.
	p processFileAsString: self file06 named: 'wordcloud_cli.py'.
	p resolveDependencies.
	
	self assert: p numberOfModules equals: 5.
	
	m1 := p moduleNamed: 'wordcloud.py'.
	m2 := p moduleNamed: 'wordcloud_cli.py'.
	self assert: m1 dependentModules size equals: 2.
	self assert: m1 dependentModules first equals: m2.
	self assert: m2 dependentModules size equals: 0.
]

{ #category : #tests }
PyProcessorTest >> testBasic04 [
	| m1 |
	p processFileAsString: self file02 named: 'wordcloud.py'.
	p processFileAsString: self file03 named: 'init.py'.
	p processFileAsString: self file04 named: 'color_from_image.py'.
	p processFileAsString: self file05 named: 'tokenization.py'.
	p processFileAsString: self file06 named: 'wordcloud_cli.py'.
	p resolveDependencies.
	
	m1 := p moduleNamed: 'init'.
	
	self assert: m1 equals: nil.
	m1 := p moduleNamed: 'init.py'.
	self assert: m1 notNil.
	
	self assert: m1 importedFilenames size equals: 2.
	self assert: m1 importedFiles size equals: 2.
]

{ #category : #tests }
PyProcessorTest >> testBasic05 [
	| m1 |
	p processFileAsString: self file02 named: 'wordcloud.py'.
	p resolveDependencies.
	m1 := p moduleNamed: 'wordcloud.py'.
	self assert: m1 filename equals: 'wordcloud.py'.
	self assert: (m1 fileReference isKindOf: FileReference).
]

{ #category : #tests }
PyProcessorTest >> testBasic06 [
	| m1 ff |
ff := '
"""
from my world is your world
"""
'.
	p processFileAsString: ff named: 'wordcloud.py'.
	p resolveDependencies.
	m1 := p moduleNamed: 'wordcloud.py'.
	self assert: m1 filename equals: 'wordcloud.py'.
	self assert: (m1 fileReference isKindOf: FileReference).
]

{ #category : #tests }
PyProcessorTest >> testBasic07 [
	| m1 ff relevantLines |
ff := '
"""
from my world is your world
"""
'.
	relevantLines := PyFile new getRelevantLinesOf: ff lines.
	self assert: relevantLines size equals: 2.
]

{ #category : #'tests - import' }
PyProcessorTest >> testFromImport [
	| f1 f2 f3 main foobar schemaMapper |
	f1 := 'from schemaMapper import zork
from foobar import foo

if __name__ == ''__main__'':
    print(''Foo = %d'' % (foo(zork())))
'.

	f2 := '
def foo(n):
    return 42 + n
'.

	f3 := 'def zork():
    return 5
'.

	p processFileAsString: f1 named: 'main.py'.
	p processFileAsString: f2 named: 'foobar.py'.
	p processFileAsString: f3 named: 'schemaMapper.py'.
	p resolveDependencies.
	
	self assert: p numberOfModules equals: 3.
	main := p moduleNamed: 'main.py'.
	foobar := p moduleNamed: 'foobar.py'.
	schemaMapper := p moduleNamed: 'schemaMapper.py'.
	
	self assert: main importedFilenames equals: #('schemaMapper' 'foobar').
	self assert: main importedFiles size equals: 2.
	self assert: main importedFiles first equals: schemaMapper.
	self assert: main importedFiles second equals: foobar.
]

{ #category : #'tests - import' }
PyProcessorTest >> testFromImportAs [
	"This semantic is not clear to me.... We need to work on this"
	| f1 f2 f3 main foobar schemaMapper |
	f1 := 'import schemaMapper as s
import foobar as bar

if __name__ == ''__main__'':
    print(''Foo = %d'' % (bar.foo(s.zork())))
'.

	f2 := '
def foo(n):
    return 42 + n
'.

	f3 := 'def zork():
    return 5
'.

	p processFileAsString: f1 named: 'main.py'.
	p processFileAsString: f2 named: 'rep/foobar.py'.
	p processFileAsString: f3 named: 'rep/schemaMapper.py'.
	p resolveDependencies.
	
	self assert: p numberOfModules equals: 3.
	main := p moduleNamed: 'main.py'.
	foobar := p moduleNamed: 'foobar.py'.
	schemaMapper := p moduleNamed: 'schemaMapper.py'.
	
	self assert: main importedFilenames equals: #('schemaMapper' 'foobar').
	self assert: main importedFiles size equals: 2.
	self assert: main importedFiles first equals: schemaMapper.
	self assert: main importedFiles second equals: foobar.
]

{ #category : #'tests - import' }
PyProcessorTest >> testFromImportWithStar [
	"This semantic is not clear to me.... We need to work on this"
	| f1 f2 f3 main foobar schemaMapper |
	f1 := 'from .rep.schemaMapper import *
from .rep.foobar import *

if __name__ == ''__main__'':
    print(''Foo = %d'' % (foo(zork())))
'.

	f2 := '
def foo(n):
    return 42 + n
'.

	f3 := 'def zork():
    return 5
'.

	p processFileAsString: f1 named: 'main.py'.
	p processFileAsString: f2 named: 'rep/foobar.py'.
	p processFileAsString: f3 named: 'rep/schemaMapper.py'.
	p resolveDependencies.
	
	self assert: p numberOfModules equals: 3.
	main := p moduleNamed: 'main.py'.
	foobar := p moduleNamed: 'foobar.py'.
	schemaMapper := p moduleNamed: 'schemaMapper.py'.
	
	self assert: main importedFilenames equals: #('.rep.schemaMapper' '.rep.foobar').
	self assert: main importedFiles size equals: 2.
	self assert: main importedFiles first equals: schemaMapper.
	self assert: main importedFiles second equals: foobar.
]

{ #category : #'tests - functions parsing' }
PyProcessorTest >> testFunctions01 [
 
	| firstFile functions |
	p processFileAsString: self file05 named: 'tokenization.py'.
	self assert: p numberOfFunctions equals: 5.
	firstFile := p files values first.
	self assert: firstFile numberOfFunctions equals: 5.
	
	functions := firstFile functions.
	self assert: functions equals: p functions.
	self assert: functions first name equals: 'l'.
	self assert: functions second name equals: 'score'.
	self assert: functions last name equals: 'process_tokens'.
	
	self assert: functions first numberOfLinesOfCode equals: 7.
	self assert: functions third numberOfLinesOfCode equals: 9.
	self assert: functions last numberOfLinesOfCode equals: 62.
]

{ #category : #'tests - functions parsing' }
PyProcessorTest >> testFunctions02CallNames [
 
	| firstFile functions firstFunction |
	p processFileAsString: self file05 named: 'tokenization.py'.
	firstFile := p files values first.
	functions := firstFile functions.
	firstFunction := functions first.
	
	self assert: firstFunction name equals: 'l'.
	self assert: firstFunction callNames asArray equals: (Array with: 'log' with: 'max' with: 'log' with: 'max')
]

{ #category : #'tests - import' }
PyProcessorTest >> testImport [
	| f1 f2 f3 main foobar schemaMapper |
	f1 := 'import schemaMapper
import foobar

if __name__ == ''__main__'':
    print(''Foo = %d'' % (foobar.foo(schemaMapper.zork())))
'.

	f2 := '
def foo(n):
    return 42 + n
'.

	f3 := 'def zork():
    return 5
'.

	p processFileAsString: f1 named: 'main.py'.
	p processFileAsString: f2 named: 'foobar.py'.
	p processFileAsString: f3 named: 'schemaMapper.py'.
	p resolveDependencies.
	
	self assert: p numberOfModules equals: 3.
	main := p moduleNamed: 'main.py'.
	foobar := p moduleNamed: 'foobar.py'.
	schemaMapper := p moduleNamed: 'schemaMapper.py'.
	
	self assert: main importedFilenames equals: #('schemaMapper' 'foobar').
	self assert: main importedFiles size equals: 2.
	self assert: main importedFiles first equals: schemaMapper.
	self assert: main importedFiles second equals: foobar.
]

{ #category : #'tests - functions parsing' }
PyProcessorTest >> testNoFunctions [
 
	self assert: p numberOfFunctions equals: 0.
	
]

{ #category : #'tests - oop' }
PyProcessorTest >> testOOP00 [

	| m |
	p processFileAsString: '' named: 'emptyFile.py'.
	m := p modules anyOne.
	self deny: m containsMain.
	
	self assert: m numberOfClasses equals: 0.
	self assert: m numberOfMethods equals: 0
]

{ #category : #'tests - oop' }
PyProcessorTest >> testOOP01 [

	| m firstClass secondClass |
	p processFileAsString: self codeOOP named: 'codeOOP.py'.
	self assert: p numberOfClasses equals: 2.
	
	m := p modules anyOne.
	self assert: m containsMain.
	
	self assert: m numberOfClasses equals: 2.
	self assert: m numberOfMethods equals: 3.
	
	firstClass := m classes first.
	self assert: firstClass name equals: 'Foo'.
	self assert: firstClass superclassName equals: 'object'.
	self assert: firstClass numberOfMethods equals: 2.
	self assert: firstClass methods first name equals: 'getValue'.
	self assert: firstClass methods first numberOfLinesOfCode equals: 3.
	self assert: firstClass methods second name equals: 'fibonacci'.
	self assert: firstClass methods second numberOfLinesOfCode equals: 6.

	secondClass := m classes second.
	self assert: secondClass name equals: 'Bar'.
	self assert: secondClass superclassName equals: 'Foo'.
	self assert: secondClass numberOfMethods equals: 1.
	self assert: secondClass methods first name equals: 'foo'.
	self assert: secondClass methods first numberOfLinesOfCode equals: 3.
	
	"Check for the superclass link"
	self assert: firstClass superclass isNil.
	self assert: secondClass superclass isNil.
	p resolveDependencies.
	self assert: firstClass superclass isNil.
	self assert: secondClass superclass notNil.
	self assert: secondClass superclass equals: firstClass.


	"Check for methods callNames"
	self assert: firstClass methods first callNames asArray equals: (Array with: 'fibonacci').
	self assert: firstClass methods second callNames asArray equals: (Array with: 'fibonacci' with: 'fibonacci').	
	
	self assert: secondClass methods first callNames isEmpty
]

{ #category : #'tests - oop' }
PyProcessorTest >> testOOP02NoSuperclass [

	| f |
	f := '
class Foo():
'.
	p processFileAsString: f named: 'codeOOP.py'.
	p resolveDependencies.
	self assert: p numberOfClasses equals: 1.
	
	self assert: p classes first superclassName equals: 'object'
]

{ #category : #'tests - oop' }
PyProcessorTest >> testOOP03 [

	| f |
	f := '
class Foo():
'.
	p processFileAsString: f named: 'codeOOP.py'.
	p resolveDependencies.
	self assert: p numberOfClasses equals: 1.
	
	self assert: p classes first superclassName equals: 'object'.
	self assert: p classes first file equals: p files values first.
]

{ #category : #'tests - oop' }
PyProcessorTest >> testOOP04ClassesAndFunctions [

	| f class |
	f := '
class Foo():
	def foo():
		return 42
def zork():
	return 5
'.
	p processFileAsString: f named: 'codeOOP.py'.
	p resolveDependencies.
	self assert: p numberOfClasses equals: 1.
	
	class := p classes first.
	self assert: class superclassName equals: 'object'.
	self assert: class file equals: p files values first.
	
	self assert: class file numberOfClasses equals: 1.
	self assert: class file numberOfFunctions equals: 1.
	self assert: class numberOfLinesOfCode equals: 3.
	
]

{ #category : #'tests - oop' }
PyProcessorTest >> testOOP05ClassesAndFunctions02 [

	| f class |
	f := '
class Foo():
	def foo():
		return 42


def zork():
	return 5
'.
	p processFileAsString: f named: 'codeOOP.py'.
	p resolveDependencies.
	self assert: p numberOfClasses equals: 1.
	
	class := p classes first.
	self assert: class superclassName equals: 'object'.
	self assert: class file equals: p files values first.
	
	self assert: class file numberOfClasses equals: 1.
	self assert: class file numberOfFunctions equals: 1.
	self assert: class numberOfLinesOfCode equals: 5.
	
]

{ #category : #'tests - oop' }
PyProcessorTest >> testOOP06LargeClass [

	| class |
	p processFileAsString: self angleUtility named: 'angle_utility.py'.
	p resolveDependencies.
	self assert: p numberOfClasses equals: 1.
	
	class := p classes first.
	self assert: class superclassName equals: 'object'.
	self assert: class file equals: p files values first.
	
	self assert: class file numberOfClasses equals: 1.
	self assert: class file numberOfFunctions equals: 23.
	
	self assert: class startLine equals: 29.
	self assert: class endLine equals: 279.
	self assert: class numberOfLinesOfCode equals: (279 - 29 + 1).
	
]

{ #category : #'tests - oop' }
PyProcessorTest >> testOOP07LargeClass [

	| class lastClass |
	p processFileAsString: self diff named: 'diff.py'.
	p resolveDependencies.
	self assert: p numberOfClasses equals: 7.
	
	class := p classes first.
	self assert: class superclassName equals: 'object'.
	self assert: class file equals: p files values first.
	
	self assert: class file numberOfClasses equals: 7.
	self assert: class file numberOfFunctions equals: 4.
	
	self assert: class startLine equals: 54.
	self assert: class endLine equals: 205.
	self assert: class numberOfLinesOfCode equals: (205 - 54 + 1).
	
	self assert: class name equals: '_BaseDiff'.
	self assert: class superclassName equals: 'object'.
	
	lastClass := p classes last.
	self assert: lastClass name equals: 'TableDataDiff'.
	self assert: lastClass superclassName equals: '_BaseDiff'.
	self assert: lastClass superclass equals: class
	
]

{ #category : #'tests - oop' }
PyProcessorTest >> testOOP08LargeClass [

	| class |
	p processFileAsString: self printers named: 'printers.py'.
	p resolveDependencies.
	self assert: p numberOfClasses equals: 1.

	class := p classes first.
	self assert: class superclassName equals: 'optparse.OptionParser'.
	self assert: class numberOfMethods equals: 3.
	
	p classes do: [ :c | 
		self assert: (c methods allSatisfy: [ :m | m numberOfLinesOfCode > 1 ]) ]
]

{ #category : #tests }
PyProcessorTest >> testRelevantLines01 [
	| ff relevantLines |
ff := '
"""from my world is your world"""
'.
	relevantLines := PyFile new getRelevantLinesOf: ff lines.
	self assert: relevantLines size equals: 2.
	self assert: relevantLines first equals: ''.
	self assert: relevantLines second equals: '"""from my world is your world"""'.
]

{ #category : #tests }
PyProcessorTest >> testRelevantLines02 [
	| ff relevantLines |
ff := '
"""
from my world is your world
"""
'.
	relevantLines := PyFile new getRelevantLinesOf: ff lines.
	self assert: relevantLines size equals: 2.
]
